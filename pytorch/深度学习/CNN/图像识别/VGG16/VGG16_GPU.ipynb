{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0527b93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a133499",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (952090355.py, line 40)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_7051/952090355.py\"\u001b[0;36m, line \u001b[0;32m40\u001b[0m\n\u001b[0;31m    train_XX[:,i,:,:]=train_X[:,:,:,i]\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda:0')\n",
    "path=\"/content/drive/My Drive/Colab Notebooks/data/dog_vs_cat/\"\n",
    "\n",
    "train_X=np.empty((2000,224,224,3),dtype=\"float32\")\n",
    "train_Y=np.empty((2000,),dtype=\"int\")\n",
    "train_XX=np.empty((2000,3,224,224),dtype=\"float32\")\n",
    "\n",
    "for i in range(1000):\n",
    "    file_path=path+\"cat.\"+str(i)+\".jpg\"\n",
    "    image=Image.open(file_path)\n",
    "    resized_image = image.resize((224, 224), Image.ANTIALIAS)\n",
    "    img=np.array(resized_image)\n",
    "    train_X[i,:,:,:]=img\n",
    "    train_Y[i]=0\n",
    "\n",
    "for i in range(1000):\n",
    "    file_path=path+\"dog.\"+str(i)+\".jpg\"\n",
    "    image = Image.open(file_path)\n",
    "    resized_image = image.resize((224, 224), Image.ANTIALIAS)\n",
    "    img = np.array(resized_image)\n",
    "    train_X[i+1000, :, :, :] = img\n",
    "    train_Y[i+1000] = 1\n",
    "\n",
    "train_X /= 255\n",
    "\n",
    "index = np.arange(2000)\n",
    "np.random.shuffle(index)\n",
    "\n",
    "train_X = train_X[index, :, :, :]\n",
    "train_Y = train_Y[index]\n",
    "\n",
    "for i in range(3):\n",
    "train_XX[:,i,:,:]=train_X[:,:,:,i]\n",
    "# 创建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49596d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "            self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(num_features=64, eps=1e-05, momentum=0.1, affine=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128,eps=1e-5,momentum=0.1,affine=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256,eps=1e-5, momentum=0.1, affine=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512, eps=1e-5, momentum=0.1, affine=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512, eps=1e-5, momentum=0.1, affine=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.dense1 = nn.Sequential(\n",
    "            nn.Linear(7*7*512,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096,4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096,2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.conv3(x)\n",
    "        x=self.conv4(x)\n",
    "        x=self.conv5(x)\n",
    "        x=x.view(-1,7*7*512)\n",
    "        x=self.dense1(x)\n",
    "        return x\n",
    "\n",
    "batch_size=16\n",
    "net = Net().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0005)\n",
    "\n",
    "train_loss = []\n",
    "for epoch in range(10):\n",
    "\n",
    "for i in range(2000//batch_size):\n",
    "    x=train_XX[i*batch_size:i*batch_size+batch_size]\n",
    "    y=train_Y[i*batch_size:i*batch_size+batch_size]\n",
    "\n",
    "    x = torch.from_numpy(x)  #(batch_size,input_feature_shape)\n",
    "    y = torch.from_numpy(y)  #(batch_size,label_onehot_shape)\n",
    "    x = x.cuda()\n",
    "    y = y.long().cuda()\n",
    "\n",
    "    out = net(x)\n",
    "\n",
    "    loss = criterion(out, y)   # 计算两者的误差\n",
    "    optimizer.zero_grad()    # 清空上一步的残余更新参数值\n",
    "    loss.backward()     # 误差反向传播, 计算参数更新值\n",
    "    optimizer.step()     # 将参数更新值施加到 net 的 parameters 上\n",
    "    train_loss.append(loss.item())\n",
    "\n",
    "    print(epoch, i*batch_size, np.mean(train_loss))\n",
    "    train_loss=[]\n",
    "\n",
    "total_correct = 0\n",
    "for i in range(2000):\n",
    "    x = train_XX[i].reshape(1,3,224,224)\n",
    "    y = train_Y[i]\n",
    "    x = torch.from_numpy(x)\n",
    "\n",
    "    x = x.cuda()\n",
    "    out = net(x).cpu()\n",
    "    out = out.detach().numpy()\n",
    "    pred=np.argmax(out)\n",
    "    if pred==y:\n",
    "        total_correct += 1\n",
    "    print(total_correct)\n",
    "\n",
    "acc = total_correct / 2000.0\n",
    "print('test acc:', acc)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
