{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46f942bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de42135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn包可以进行神经网络的构建\n",
    "# nn是在autograd基础上进行模型的定义和微分\n",
    "# nn.module包含着神经网络的层，同时forward（input）方法可以将output进行返回\n",
    "# torcn.nn是专门为神经网络设计的模块化接口. nn构建于autograd之上，可以用来定义和运行神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b27b187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        # nn.Module子类的函数必须在构造函数中执行父类的构造函数\n",
    "        # nn.Module.__init__(self)\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Pytorch基于nn.Module构建的模型中，只支持mini-batch的Variable输入方式。比如，只有一张输入图片，也需要变成NxCxHxW的\n",
    "        self.conv1 = nn.Conv2d(1,6,5)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        \n",
    "        # 仿射层/全连接层，y = Wx + b\n",
    "        self.fc1 = nn.Linear(16*5*5,120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
    "        x=F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x=x.view(-1,self.num_flat_features(x))\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self,x):\n",
    "        size=x.size()[1:]\n",
    "        num_features=1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "            \n",
    "# 只需要定义一个forward函数，backward会自动生成，可以在forward函数中使用所有tensor操作\n",
    "# 参数的模型由net.parameters()返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cb549da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n神经网络的输出结果是这样的\\nNet (\\n(conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\\n(conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\\n(fc1): Linear (400 -> 120)\\n(fc2): Linear (120 -> 84)\\n(fc3): Linear (84 -> 10)\\n)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "神经网络的输出结果是这样的\n",
    "Net (\n",
    "(conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
    "(conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
    "(fc1): Linear (400 -> 120)\n",
    "(fc2): Linear (120 -> 84)\n",
    "(fc3): Linear (84 -> 10)\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66807f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([16, 6, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([120, 400])\n",
      "torch.Size([120])\n",
      "torch.Size([84, 120])\n",
      "torch.Size([84])\n",
      "torch.Size([10, 84])\n",
      "torch.Size([10])\n",
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([1, 1, 32, 32])\n",
      "tensor([[[[-1.4007,  0.1783,  0.9760,  ...,  0.3358, -0.9377,  0.8576],\n",
      "          [-1.8519,  0.5645,  1.4357,  ...,  0.7488,  1.3770,  1.1279],\n",
      "          [ 1.1647, -0.8626, -3.1895,  ...,  1.7776, -0.3026,  1.3552],\n",
      "          ...,\n",
      "          [ 0.6039,  0.5879,  1.2493,  ...,  1.7790,  1.3006,  0.9405],\n",
      "          [-0.3199, -1.6383, -0.5232,  ...,  1.0847, -0.4661, -0.5179],\n",
      "          [-0.9115,  0.3669, -1.1777,  ..., -0.6355, -0.7244,  0.7984]]]])\n",
      "tensor([[-0.0170, -0.0965, -0.0349, -0.0286, -0.1105,  0.0536, -0.1077, -0.1030,\n",
      "         -0.0251, -0.0886]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "params = list(net.parameters())\n",
    "print(len(params))   # 10\n",
    "\n",
    "for param in params:\n",
    "    print(param.size())\n",
    "print(params[0].size()) # conv1's .weight: torch.Size([6, 1, 5, 5])\n",
    "input = Variable(torch.randn(1, 1, 32, 32))  # 为什么这里是四通道？\n",
    "# tensorSamples * nChannels * height * width\n",
    "print(input.size())\n",
    "print(input)\n",
    "out = net.forward(input)  # net.forward\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "733e2219",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04f5fcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiang/anaconda3/envs/pytorch_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  \"\"\"\n",
      "/home/xiang/anaconda3/envs/pytorch_gpu/lib/python3.7/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([10])) that is different to the input size (torch.Size([1, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# 已经定义了一个神经网络，处理了输入以及实现了反馈\n",
    "# 仍未定义代价函数，计算代价，更新网络权重\n",
    "# 代价函数：接收（输出，目标）对作为输入，计算出输出和目标之间差距作为代价函数输出\n",
    "output = net(input)\n",
    "target = Variable(torch.range(1,10))  # a dummy target, for example\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b540e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d -> view -> linear -> relu -> linear -> relu -> linear -> MSELoss -> loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b89b3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x7f2fddb0cc90>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MseLossBackward' object has no attribute 'previous_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2540/1353646535.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# MSELoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevious_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Linear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevious_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevious_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MseLossBackward' object has no attribute 'previous_functions'"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn) # MSELoss\n",
    "print(loss.grad_fn.previous_functions[0][0]) # Linear\n",
    "print(loss.grad_fn.previous_functions[0][0].previous_functions[0][0]) # ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d7c00f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
