{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "506f641f",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ff24157c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor([0., 0., 0.])\n",
      "tensor([1., 1., 1.])\n",
      "torch.Size([4, 3, 2, 2])\n",
      "BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "tensor([0.0151, 0.0008, 0.0269])\n",
      "tensor([0.9738, 1.0608, 1.0294])\n"
     ]
    }
   ],
   "source": [
    "bn = nn.BatchNorm2d(3, track_running_stats=True)  # momentum=0.1是默认的\n",
    "print(bn)\n",
    "print(bn.running_mean)\n",
    "print(bn.running_var)\n",
    "\n",
    "x = torch.randn(4, 3, 2, 2)\n",
    "y = bn(x)\n",
    "# print(x)\n",
    "# print(y)\n",
    "print(y.size())\n",
    "print(bn)\n",
    "print(bn.running_mean)\n",
    "print(bn.running_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0cfd2dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean value of the first channel is -0.486114\n",
      "The mean value of the second channel is -0.177291\n",
      "The mean value of the third channel is 0.145817\n",
      "The output mean value of the BN layer is -0.048611, -0.017729, 0.014582\n",
      "The output var value of the BN layer is 0.981166, 0.958100, 0.996654\n"
     ]
    }
   ],
   "source": [
    "a = (x[0, 0, :, :] + x[1, 0, :, :] + x[2, 0, :, :] + x[3, 0, :, :]).sum() / 16\n",
    "b = (x[0, 1, :, :] + x[1, 1, :, :] + x[2, 1, :, :] + x[3, 1, :, :]).sum() / 16\n",
    "c = (x[0, 2, :, :] + x[1, 2, :, :] + x[2, 2, :, :] + x[3, 2, :, :]).sum() / 16\n",
    "print('The mean value of the first channel is %f' % a.data)\n",
    "print('The mean value of the second channel is %f' % b.data)\n",
    "print('The mean value of the third channel is %f' % c.data)\n",
    "print('The output mean value of the BN layer is %f, %f, %f' % (bn.running_mean.data[0], bn.running_mean.data[1], bn.running_mean.data[2]))\n",
    "print('The output var value of the BN layer is %f, %f, %f' % (bn.running_var.data[0], bn.running_var.data[1], bn.running_var.data[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bbd5215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n第一个通道的running_mean正好是真实的mean的0.1倍\\n因为在最开始的时候running_mean=0，然后用滑动平均公式去更新：\\nrunning_mean=0.9∗running_mean+0.1∗mean=0.1∗mean\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "第一个通道的running_mean正好是真实的mean的0.1倍. 同理running_var\n",
    "因为在最开始的时候running_mean=0，然后用滑动平均公式去更新：\n",
    "running_mean=0.9∗running_mean+0.1∗mean=0.1∗mean\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b48afb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean value of the first channel is 0.085720\n",
      "The mean value of the first channel is 0.178778\n",
      "The mean value of the first channel is 0.379047\n",
      "The output mean value of the BN layer is 0.016287, 0.033968, 0.072019\n",
      "running_mean: tensor([0.0163, 0.0340, 0.0720])\n",
      "running_var: tensor([1.1124, 0.8708, 0.9671])\n"
     ]
    }
   ],
   "source": [
    "# 那么当我们前向传播两次之后，再来观察running_mean和mean的关系。\n",
    "# running_mean=0.9∗(0.9∗0+0.1∗mean)+0.1∗mean=0.19∗mean\n",
    "bn = nn.BatchNorm2d(3)\n",
    "x = torch.randn(4, 3, 2, 2)\n",
    "y = bn(x)\n",
    "y = bn(x)  # 前向传播两次\n",
    "a = (x[0, 0, :, :] + x[1, 0, :, :] + x[2, 0, :, :] + x[3, 0, :, :]).sum() / 16\n",
    "b = (x[0, 1, :, :] + x[1, 1, :, :] + x[2, 1, :, :] + x[3, 1, :, :]).sum() / 16\n",
    "c = (x[0, 2, :, :] + x[1, 2, :, :] + x[2, 2, :, :] + x[3, 2, :, :]).sum() / 16\n",
    "print('The mean value of the first channel is %f' % a.data)\n",
    "print('The mean value of the first channel is %f' % b.data)\n",
    "print('The mean value of the first channel is %f' % c.data)\n",
    "print('The output mean value of the BN layer is %f, %f, %f' % (bn.running_mean.data[0], bn.running_mean.data[1], bn.running_mean.data[2]))\n",
    "print(\"running_mean:\", bn.running_mean)\n",
    "print(\"running_var:\", bn.running_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "26bc48ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: [3. 3. 4. 2.]\n",
      "ddof = 0 -> 有样本方差/标准差。|| ddof = 1 -> 无样本方差/标准差。\n",
      "variance(1): [7. 1. 4. 3.]\n",
      "std(1): [2.64575131 1.         2.         1.73205081]\n",
      "variance(0): [4.66666667 0.66666667 2.66666667 2.        ]\n",
      "std(0): [2.1602469  0.81649658 1.63299316 1.41421356]\n",
      "\n",
      "=============================================\n",
      "有偏和无偏的区别在于无偏的分母是N-1，有偏的分母是N。注意在BatchNorm中，用于更新running_var时，使用无偏样本方差即，但是在对batch进行归一化时，使用有偏样本方差，因此如果batch_size=1，会报错。\n",
      "=============================================\n",
      "\n",
      "初始化的running_mean,shape取决于你的chs: tensor([0., 0., 0., 0.])\n",
      "初始化的running_var,shape取决于你的chs: tensor([1., 1., 1., 1.])\n",
      "torch.Size([1, 1, 3, 4])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 1 elements not 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3992/1920265659.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1668\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1669\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1670\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1671\u001b[0m     )\n\u001b[1;32m   1672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 1 elements not 4"
     ]
    }
   ],
   "source": [
    "import numpy, torch\n",
    "a = numpy.array([[1, 2, 4, 1],[6, 3, 2, 4],[2, 4, 6, 1]])\n",
    "# print(a.size())\n",
    "print(\"mean:\", a.mean(0))\n",
    "print(\"ddof = 0 -> 有样本方差/标准差。|| ddof = 1 -> 无样本方差/标准差。\")\n",
    "print(\"variance(1):\", a.var(0, ddof=1))\n",
    "print(\"std(1):\", a.std(0, ddof=1))\n",
    "print(\"variance(0):\", a.var(0, ddof=0))\n",
    "print(\"std(0):\", a.std(0, ddof=0))\n",
    "\n",
    "print(\"\\n\" + \"=========\"*5)\n",
    "print(\"有偏和无偏的区别在于无偏的分母是N-1，有偏的分母是N。注意在BatchNorm中，用于更新running_var时，使用无偏样本方差即，但是在对batch进行归一化时，使用有偏样本方差，因此如果batch_size=1，会报错。\")\n",
    "print(\"=========\"*5 + \"\\n\")\n",
    "\n",
    "a = torch.tensor([[1., 2., 4., 1.],[6., 3., 2., 4.],[2., 4., 6., 1.]])\n",
    "\n",
    "bn = torch.nn.BatchNorm2d(4) # 注意torch都是要操作4D的数据的\n",
    "print(\"初始化的running_mean,shape取决于你的chs:\", bn.running_mean)\n",
    "print(\"初始化的running_var,shape取决于你的chs:\", bn.running_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b05cf2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
