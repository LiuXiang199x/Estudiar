{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55a52784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8dece5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view/reshape都是用来重塑tensor的shape。view只适合对满足连续性条件(contiguous)的tensor进行操作\n",
    "# 而reshape同时还可以对不满足连续性条件的tensor进行操作，具有更好的鲁棒性。view能干的reshape都能干\n",
    "# 连续是指：数据在内存中的储存是连续的！!!\n",
    "# 如果对 tensor 调用过 transpose, permute等操作的话会使该 tensor 在内存中变得不再连续。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df231d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([[ 1.8701, -0.1310,  1.9693, -0.1261],\n",
      "        [-0.9996,  0.7786, -0.7518,  1.2747],\n",
      "        [-0.1925,  1.4946,  0.2240,  0.4336]])\n",
      "b: tensor([[[[-0.6930,  0.3708,  1.3526, -1.4093],\n",
      "          [-0.4589,  0.0636, -1.5560, -0.6054],\n",
      "          [-0.9997,  0.0355,  0.3142, -0.1524]]]])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([1, 1, 3, 4])\n",
      "a after permute: tensor([[ 1.8701, -0.9996, -0.1925],\n",
      "        [-0.1310,  0.7786,  1.4946],\n",
      "        [ 1.9693, -0.7518,  0.2240],\n",
      "        [-0.1261,  1.2747,  0.4336]])\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3,4)\n",
    "b = torch.randn(1,1,3,4)\n",
    "print(\"a:\",a)\n",
    "print(\"b:\",b)\n",
    "print(a.size())\n",
    "print(b.size())\n",
    "a = a.permute(1,0)   # permute 维度调换\n",
    "print(\"a after permute:\",a)\n",
    "print(a.is_contiguous())\n",
    "print(b.is_contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3457c222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------b.view------\n",
      "tensor([[ 1.6453, -0.2028, -0.3278,  0.6148, -0.2608, -1.2393, -0.3651, -1.4164,\n",
      "          0.7430, -0.4121,  0.4426, -1.1172]])\n",
      "tensor([[ 1.6453, -0.2028, -0.3278,  0.6148, -0.2608, -1.2393],\n",
      "        [-0.3651, -1.4164,  0.7430, -0.4121,  0.4426, -1.1172]])\n",
      "\n",
      "--------b.reshape-------\n",
      "tensor([[ 1.6453, -0.2028, -0.3278,  0.6148, -0.2608, -1.2393, -0.3651, -1.4164,\n",
      "          0.7430, -0.4121,  0.4426, -1.1172]])\n",
      "tensor([[ 1.6453, -0.2028, -0.3278,  0.6148, -0.2608, -1.2393],\n",
      "        [-0.3651, -1.4164,  0.7430, -0.4121,  0.4426, -1.1172]])\n",
      "\n",
      "-------view和reshape出来的都必须刚好使用所有数据，resize_不一样，它可以截取一段------\n",
      "tensor([[ 1.6453, -0.2028],\n",
      "        [-0.3278,  0.6148]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.randn(1,1,3,4)\n",
    "\n",
    "print(\"------b.view------\")\n",
    "print(b.view(1, -1))\n",
    "print(b.view(2, -1))\n",
    "\n",
    "print(\"\\n--------b.reshape-------\")\n",
    "print(b.reshape(1,-1))\n",
    "print(b.reshape(2,-1))\n",
    "\n",
    "print(\"\\n-------view和reshape出来的都必须刚好使用所有数据，resize_不一样，它可以截取一段------\")\n",
    "# print(b.resize_(1,-1))   # resize_就不能用 自适应-1\n",
    "print(b.resize_(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e8044e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
