{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3075f460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "892e5ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy Loss:\n",
      "  tensor([1.3133, 0.1269, 0.1269]) tensor(1.5671) tensor(0.5224)\n",
      "\n",
      "weights:  tensor([1., 2.])\n",
      "tensor([1.3133, 0.2539, 0.2539]) tensor(1.8210) tensor(0.3642)\n"
     ]
    }
   ],
   "source": [
    "# CrossEntropyLoss\n",
    "# 构建虚拟数据 batch_size=3即3个样本\n",
    "inputs = torch.tensor([[1, 2], [1, 3], [1, 3]], dtype=torch.float)\n",
    "# 设置标签、类型为长整型，第1个样本为第0类，第2、3个样本为第1类，注意类别数class是从0算起的\n",
    "target = torch.tensor([0, 1, 1], dtype=torch.long)\n",
    "\n",
    "# 通过nn.CrossEntropyLoss构造损失函数，观察3种reduction模式下Loss计算\n",
    "# ------------------- CrossEntropy loss: reduction ---------------------\n",
    "\"\"\"\n",
    "weight:各个类别的Loss设置权值\n",
    "ignore_index:忽略某个类别\n",
    "reduction:计算模式可为none/sum/mean\n",
    "none-逐个元素计算\n",
    "sum-所有元素求和，返回标量\n",
    "mean-加权平均，返回标量\n",
    "\"\"\"\n",
    "# def loss function # 维度上不衰减，有3个样本就有3个Loss\n",
    "loss_f_none = nn.CrossEntropyLoss(weight=None, reduction='none')  \n",
    "# 求和模式：把所有样本的Loss加起来\n",
    "loss_f_sum = nn.CrossEntropyLoss(weight=None, reduction='sum')   \n",
    "# 默认模式-均分\n",
    "loss_f_mean = nn.CrossEntropyLoss(weight=None, reduction='mean')   \n",
    "\n",
    "# forward\n",
    "loss_none = loss_f_none(inputs, target)\n",
    "loss_sum = loss_f_sum(inputs, target)\n",
    "loss_mean = loss_f_mean(inputs, target)\n",
    "\n",
    "# view\n",
    "print(\"Cross Entropy Loss:\\n \", loss_none, loss_sum, loss_mean)\n",
    "\n",
    "# def loss function\n",
    "# weight设置时需要注意是“向量形式”，有多少个类别就需要设置多长的向量，每个类别都需要设置weight,不想关注的类别可以设置为1.设置weight,不需要关注尺度，只需要关注各类别之间的比例。\n",
    "# 设置第0类权重为1，第1类权重为2\n",
    "weights = torch.tensor([1, 2], dtype=torch.float)\n",
    "# weights = torch.tensor([0.7, 0.3], dtype=torch.float)\n",
    "\n",
    "loss_f_none_w = nn.CrossEntropyLoss(weight=weights, reduction='none')\n",
    "loss_f_sum = nn.CrossEntropyLoss(weight=weights, reduction='sum')\n",
    "loss_f_mean = nn.CrossEntropyLoss(weight=weights, reduction='mean')\n",
    "\n",
    "# forward\n",
    "loss_none_w = loss_f_none_w(inputs, target)\n",
    "loss_sum = loss_f_sum(inputs, target)\n",
    "loss_mean = loss_f_mean(inputs, target)\n",
    "\n",
    "# view\n",
    "print(\"\\nweights: \", weights)\n",
    "print(loss_none_w, loss_sum, loss_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d168da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4367, 0.3523, 1.1874]) tensor([1., 1., 0.])\n",
      "tensor(0.7573)\n",
      "tensor(0.7573)\n"
     ]
    }
   ],
   "source": [
    "# loss中都是 prediction在前，target在后\n",
    "# L1Loss(), 绝对值误差\n",
    "\n",
    "x = torch.randn(3)\n",
    "y = torch.tensor([1., 1., 0.])\n",
    "print(x, y)\n",
    "l1loss = nn.L1Loss()\n",
    "a = 0\n",
    "print(l1loss(x, y))\n",
    "for i in range(len(x)):\n",
    "    a += abs(x[i]-y[i])\n",
    "print(a/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82f5f9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1507, -0.3613,  0.0976]) tensor([1., 1., 0.])\n",
      "tensor(1.0623)\n",
      "tensor(1.0623)\n"
     ]
    }
   ],
   "source": [
    "# loss中都是 prediction在前，target在后\n",
    "# MSELoss:平方损失的平均值()\n",
    "x = torch.randn(3)\n",
    "y = torch.tensor([1., 1., 0.])\n",
    "print(x, y)\n",
    "mseloss = nn.MSELoss()   # loss 是prediction和target之间的关系\n",
    "print(mseloss(x, y))\n",
    "a = 0\n",
    "for i in range(len(x)):\n",
    "    a += (y[i]-x[i])**2\n",
    "print(a/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45c3b389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1., -3., -3.]) tensor(-7.) tensor(-2.3333)\n"
     ]
    }
   ],
   "source": [
    "# NLLLoss()\n",
    "inputs = torch.tensor([[1, 2], [1, 3], [1, 3]], dtype=torch.float)\n",
    "target = torch.tensor([0, 1, 1], dtype=torch.long)\n",
    "\n",
    "weights = torch.tensor([1, 1], dtype=torch.float)\n",
    "\n",
    "loss_f_none_w = nn.NLLLoss(weight=weights, reduction='none')\n",
    "loss_f_sum = nn.NLLLoss(weight=weights, reduction='sum')\n",
    "loss_f_mean = nn.NLLLoss(weight=weights, reduction='mean')\n",
    "print(loss_f_none_w(inputs, target), \n",
    "      loss_f_sum(inputs, target), \n",
    "      loss_f_mean(inputs, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "536a2e2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3958/83405680.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mloss_none_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_f_none_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_bce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mloss_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_f_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_bce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mloss_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_f_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_bce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_gpu/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_gpu/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_gpu/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2891\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2893\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "# BCELoss():二分类，多分类都可以，其实就是多分类！！！输出在[0, 1]\n",
    "# 虚拟输入：二分类所以有2个神经元，4个样本，第1个样本：第1个神经元输出值为1，第2个神经元输出值为2\n",
    "inputs = torch.tensor([[1, 2], [2, 2], [3, 4], [4, 5]], dtype=torch.float)\n",
    "# BCE与CrossEntropyLoss的标签不同，是浮点类数据，每个神经元一一对应的计算Loss,而非一整个神经元向量计算Loss\n",
    "target = torch.tensor([[1, 0], [1, 0], [0, 1], [0, 1]], dtype=torch.float)\n",
    "\n",
    "target_bce = target\n",
    "\n",
    "\n",
    "weights = torch.tensor([1, 1], dtype=torch.float)\n",
    "\n",
    "loss_f_none_w = nn.BCELoss(weight=weights, reduction='none')\n",
    "loss_f_sum = nn.BCELoss(weight=weights, reduction='sum')\n",
    "loss_f_mean = nn.BCELoss(weight=weights, reduction='mean')\n",
    "\n",
    "# forward\n",
    "loss_none_w = loss_f_none_w(inputs, target_bce)\n",
    "loss_sum = loss_f_sum(inputs, target_bce)\n",
    "loss_mean = loss_f_mean(inputs, target_bce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cc2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输入值并没有在[0,1]之间，由于BCE二分类交叉熵损失函数衡量的是两个概率分布之间的差异，因此输入应当在[0,1]之间。\n",
    "# 因此，需要将输入值经过激活函数 sigmoid()进行压缩，使其输出值在(0,1)之间。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
