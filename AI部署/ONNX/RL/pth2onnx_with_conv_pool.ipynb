{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37166c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import gym\n",
    "import numpy\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from gym import wrappers\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional\n",
    "import glob\n",
    "# from base.rl.ppo import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76da0d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n",
      "1.6.0\n",
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "pthfile = 'ckpt.test.pth'\n",
    "onnxpath = 'test_conv_pool.onnx'\n",
    "print(torch.__version__)\n",
    "print(onnx.__version__)\n",
    "print(onnxruntime.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1116726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_map(h, crop_size):\n",
    "    \n",
    "#     bs = torch.tensor(1)\n",
    "#     ch = torch.tensor(4)\n",
    "#     H = torch.tensor(481)\n",
    "#     W = torch.tensor(481)\n",
    "    \n",
    "    tmp_h_0 = torch.zeros(120, 481)\n",
    "    tmp_h_1 = torch.ones(120, 481)\n",
    "    tmp_v_0 = torch.zeros(721, 120)\n",
    "    tmp_v_1 = torch.ones(721, 120)\n",
    "    \n",
    "    ############### first map ######################\n",
    "    tmp_map = h\n",
    "    # print(\"h size::\", h.size())\n",
    "    \n",
    "    tmp_h0 = torch.cat((tmp_map[0][0], tmp_h_1), dim=0)\n",
    "    tmp_h0 = torch.cat((tmp_h_1, tmp_h0), dim=0)\n",
    "    # print(\"tmp_h:\", tmp_h.size())\n",
    "\n",
    "    tmp_v0 = torch.cat((tmp_h0, tmp_v_1), dim=1)\n",
    "    tmp_v0 = torch.cat((tmp_v_1, tmp_v0), dim=1)\n",
    "    \n",
    "    ################ second map ####################\n",
    "    tmp_map = h\n",
    "    # print(\"h size::\", h.size())\n",
    "    \n",
    "    tmp_h1 = torch.cat((tmp_map[0][1], tmp_h_0), dim=0)\n",
    "    tmp_h1 = torch.cat((tmp_h_0, tmp_h1), dim=0)\n",
    "    # print(\"tmp_h:\", tmp_h.size())\n",
    "\n",
    "    tmp_v1 = torch.cat((tmp_h1, tmp_v_0), dim=1)\n",
    "    tmp_v1 = torch.cat((tmp_v_0, tmp_v1), dim=1)\n",
    "\n",
    "    ################ Third map ####################\n",
    "    tmp_map = h\n",
    "    # print(\"h size::\", h.size())\n",
    "    \n",
    "    tmp_h2 = torch.cat((tmp_map[0][2], tmp_h_0), dim=0)\n",
    "    tmp_h2 = torch.cat((tmp_h_0, tmp_h2), dim=0)\n",
    "    # print(\"tmp_h:\", tmp_h.size())\n",
    "\n",
    "    tmp_v2 = torch.cat((tmp_h2, tmp_v_0), dim=1)\n",
    "    tmp_v2 = torch.cat((tmp_v_0, tmp_v2), dim=1)\n",
    "    # print(\"tmp_v:\", tmp_v.size())\n",
    "\n",
    "    ################ Forth map ####################\n",
    "\n",
    "    # tensor_index = torch.linspace(120., 601., 481)\n",
    "    tmp_map = h\n",
    "    # print(\"h size::\", h.size())\n",
    "    \n",
    "    tmp_h3 = torch.cat((tmp_map[0][3], tmp_h_0), dim=0)\n",
    "    tmp_h3 = torch.cat((tmp_h_0, tmp_h3), dim=0)\n",
    "    # print(\"tmp_h:\", tmp_h.size())\n",
    "\n",
    "    tmp_v3 = torch.cat((tmp_h3, tmp_v_0), dim=1)\n",
    "    tmp_v3 = torch.cat((tmp_v_0, tmp_v3), dim=1)\n",
    "    \n",
    "    ################################################\n",
    "    map_tmp = torch.cat((torch.unsqueeze(tmp_v0, 0), torch.unsqueeze(tmp_v1, 0), \n",
    "                         torch.unsqueeze(tmp_v2, 0), torch.unsqueeze(tmp_v3, 0)), 0)\n",
    "    map_tmp = torch.unsqueeze(map_tmp, 0)\n",
    "    # print(\"after expanding map size:\", map_tmp.size())\n",
    "\n",
    "    ############ start crap map #####################\n",
    "    x_pos = torch.nonzero(map_tmp[0][3]==1)[:][:,0][0]\n",
    "    y_pos = torch.nonzero(map_tmp[0][3]==1)[:][:,1][0]\n",
    "    \n",
    "    \n",
    "    # print(map_tmp)\n",
    "    # print(\"x_pos:{}, y_pos:{}\".format(x_pos,y_pos))\n",
    "    # print(map_tmp.size())\n",
    "    # print(torch.nonzero(map_tmp[0][3]==1))\n",
    "    index_tensor = torch.linspace(-120, 119, 240)\n",
    "    # index_tensor = torch.tensor([-120, -119, -118, -117, -116, -115, -114, -113, -112, -111, -110, -109, -108, -107, -106, -105, -104, -103, -102, -101, -100, -99, -98, -97, -96, -95, -94, -93, -92, -91, -90, -89, -88, -87, -86, -85, -84, -83, -82, -81, -80, -79, -78, -77, -76, -75, -74, -73, -72, -71, -70, -69, -68, -67, -66, -65, -64, -63, -62, -61, -60, -59, -58, -57, -56, -55, -54, -53, -52, -51, -50, -49, -48, -47, -46, -45, -44, -43, -42, -41, -40, -39, -38, -37, -36, -35, -34, -33, -32, -31, -30, -29, -28, -27, -26, -25, -24, -23, -22, -21, -20, -19, -18, -17, -16, -15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119])\n",
    "    # index_tensor = index_tensor.long()\n",
    "    index_tensor_x = index_tensor.long() + x_pos.long()\n",
    "    index_tensor_y = index_tensor.long() + y_pos.long()\n",
    "    # print(\"index_tensor_x\", index_tensor_x)\n",
    "\n",
    "    tmp_crap_map_0 = torch.index_select(map_tmp[0][0], 1, index_tensor_y)\n",
    "    tmp_crap_map_0 = torch.index_select(tmp_crap_map_0, 0, index_tensor_x)\n",
    "    \n",
    "    tmp_crap_map_1 = torch.index_select(map_tmp[0][1], 1, index_tensor_y)\n",
    "    tmp_crap_map_1 = torch.index_select(tmp_crap_map_1, 0, index_tensor_x)\n",
    "    \n",
    "    tmp_crap_map_2 = torch.index_select(map_tmp[0][2], 1, index_tensor_y)\n",
    "    tmp_crap_map_2 = torch.index_select(tmp_crap_map_2, 0, index_tensor_x)\n",
    "    \n",
    "    tmp_crap_map_3 = torch.index_select(map_tmp[0][3], 1, index_tensor_y)\n",
    "    tmp_crap_map_3 = torch.index_select(tmp_crap_map_3, 0, index_tensor_x)\n",
    "    \n",
    "    tmp = tmp_crap_map_3\n",
    "    \n",
    "    '''\n",
    "    output = torch.cat((torch.unsqueeze(tmp_crap_map_0, 0), torch.unsqueeze(tmp_crap_map_1, 0),\n",
    "                       torch.unsqueeze(tmp_crap_map_2, 0), torch.unsqueeze(tmp_crap_map_3, 0)), 0)\n",
    "    output = torch.unsqueeze(output, 0)\n",
    "    # print(\"ouput::::\",output.size())\n",
    "    '''\n",
    "    # output = torch.randn(1, 4, crop_size, crop_size)\n",
    "    '''\n",
    "    output[0][0] = tmp_crap_map_0\n",
    "    output[0][1] = tmp_crap_map_1\n",
    "    output[0][2] = tmp_crap_map_2\n",
    "    output[0][3] = tmp_crap_map_3\n",
    "    '''\n",
    "    \n",
    "    tmp_0 = tmp_crap_map_0\n",
    "    tmp_1 = tmp_crap_map_1\n",
    "    tmp_2 = tmp_crap_map_2\n",
    "    tmp_3 = tmp_crap_map_3\n",
    "    tmp_0 = torch.reshape(tmp_0,[1,1,tmp_0.shape[0],tmp_0.shape[1]])\n",
    "    tmp_1 = torch.reshape(tmp_1,[1,1,tmp_1.shape[0],tmp_1.shape[1]])\n",
    "    tmp_2 = torch.reshape(tmp_2,[1,1,tmp_2.shape[0],tmp_2.shape[1]])\n",
    "    tmp_3 = torch.reshape(tmp_3,[1,1,tmp_3.shape[0],tmp_3.shape[1]])\n",
    "    \n",
    "    tmp = torch.cat((tmp_0,tmp_1,tmp_2,tmp_3),1)\n",
    "#     tmp_0 = torch.unsqueeze(tmp_crap_map_0, 0)\n",
    "#     tmp_1 = torch.unsqueeze(tmp_crap_map_1, 0)\n",
    "#     tmp_2 = torch.unsqueeze(tmp_crap_map_2, 0)\n",
    "#     tmp_3 = torch.unsqueeze(tmp_crap_map_3, 0)\n",
    "    \n",
    "#     tmp = torch.cat((tmp_0, tmp_1), 0)\n",
    "#     tmp = torch.cat((tmp, tmp_2), 0)\n",
    "#     tmp = torch.cat((tmp, tmp_3), 0)\n",
    "#     tmp = torch.unsqueeze(tmp, 0)\n",
    "    # print(\"tmp size:\", tmp.size())\n",
    "    \n",
    "    # tmp = torch.index_select(tmp, 0, torch.tensor([0]))\n",
    "    # print(\"tmp size:\", tmp.size())\n",
    "    # output = tmp\n",
    "    # print(\"output:\", tmp.size())\n",
    "    \n",
    "    \n",
    "    return tmp\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "class Global_Actor(nn.Module):\n",
    "    def __init__(self, G):\n",
    "        super().__init__()\n",
    "        self.G = torch.tensor(G)\n",
    "        self.actor = nn.Sequential(  # (8, G, G)\n",
    "            nn.Conv2d(8, 8, 3, padding=1),  # (8, G, G)\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 4, 3, padding=1),  # (4, G, G)\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 4, 5, padding=2),  # (4, G, G)\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 2, 5, padding=2),  # (2, G, G)\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2, 1, 5, padding=2),  # (1, G, G)\n",
    "            Flatten(),  # (G*G, )\n",
    "            nn.Sigmoid(),  # added for non-negative\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def _get_h12(self, inputs): # inputs needs to be a tensor, i.e., original inputs[\"map_at_t\"], (bs, 4, M, M), channel 3 means one-hot pose, channel 0~1 means global map\n",
    "        # x = inputs[\"pose_in_map_at_t\"]  # (bs,2)\n",
    "        # map_at_t (4, m, m)\n",
    "        # x = torch.nonzero(inputs[0][3]==1)\n",
    "        h = inputs\n",
    "        \n",
    "        h_1 = crop_map(h, self.G)\n",
    "        # print(torch.nonzero(h_1[0][3]==1))\n",
    "        h_2 = F.max_pool2d(h, (2, 2))\n",
    "# adaptive_max_pool2d\n",
    "        #print(\"h111:\", h_1.size())\n",
    "        #print(\"h22:\", h_2.size())\n",
    "    \n",
    "        h_12 = torch.cat((h_1, h_2), dim=1)\n",
    "\n",
    "        return h_12\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x1 = self._get_h12(inputs)\n",
    "        x2 = self.actor(x1)\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8156500c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['0.weight', '0.bias', '1.weight', '1.bias', '1.running_mean', '1.running_var', '3.weight', '3.bias', '4.weight', '4.bias', '4.running_mean', '4.running_var', '6.weight', '6.bias', '7.weight', '7.bias', '7.running_mean', '7.running_var', '9.weight', '9.bias', '10.weight', '10.bias', '10.running_mean', '10.running_var', '12.weight', '12.bias'], unexpected_keys=['global_state_dict', 'extra_state'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_net = Global_Actor(240)\n",
    "actor_net.actor.load_state_dict(torch.load(pthfile, map_location='cpu'),strict=False)\n",
    "    # Initialize model with the pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f015b002",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(1, 4, 481, 481)\n",
    "\n",
    "map3 = torch.zeros(1, 481, 481)\n",
    "map3[0][20][20] = 1.\n",
    "inputs[0][3] = map3\n",
    "'''\n",
    "print(map3)\n",
    "print(torch.nonzero(map3==1))\n",
    "inputs[0][3] = map3 'tensor(flo\n",
    "yy = torch.nonzero(inputs[0][3]==1)\n",
    "print(type(yy))\n",
    "print(type(yy[:,:2]))\n",
    "print(yy == yy[:,:2])\n",
    "print(x.size())\n",
    "'''\n",
    "\n",
    "x = inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d066423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    M = 481\n",
    "    model = Global_Actor(240)\n",
    "    batch_size = 1\n",
    "    input_shape = (4, M, M)\n",
    "    \n",
    "    # Initialize model with the pretrained weights\n",
    "    # map_location = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "    loaded_model = torch.load(pthfile, map_location=\"cpu\")\n",
    "    model.actor.load_state_dict(loaded_model, strict=False)\n",
    "    \n",
    "    # set the model to inference mode\n",
    "    model.eval()\n",
    "    \n",
    "    # data type nchw\n",
    "    # x = torch.rand(batch_size, *input_shape)\n",
    "\n",
    "    # # Export the model\n",
    "    torch.onnx.export(model, x, \n",
    "                      onnxpath, \n",
    "                      opset_version=10)\n",
    "                      #keep_initializers_as_inputs=True, \n",
    "                      # verbose=True\n",
    "    '''\n",
    "    torch.onnx.export(model,               # model being run\n",
    "                    x,                         # model input (or a tuple for multiple inputs)\n",
    "                    onnxpath,   # where to save the model (can be a file or file-like object)\n",
    "                    export_params=True,        # store the trained parameter weights inside the model file\n",
    "                    opset_version=10,          # the ONNX version to export the model to\n",
    "                    do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                    input_names = ['input'],   # the model's input names\n",
    "                    output_names = ['output'], # the model's output names\n",
    "                    dynamic_axes={'input' : {0 : 'batch_size'},    # variable lenght axes\n",
    "                                  'output' : {0 : 'batch_size'}}\n",
    "                     )\n",
    "    '''\n",
    "    print(\"=============Successful==========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c1e9656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============Successful==========\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7082981b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.2478, -1.2804],\n",
      "          [ 1.0480, -0.0234]],\n",
      "\n",
      "         [[ 0.2194,  0.7509],\n",
      "          [-0.2113,  0.3923]],\n",
      "\n",
      "         [[ 1.0334,  0.2553],\n",
      "          [ 0.7283, -1.0217]]]])\n",
      "tensor([[[[-1.5599, -0.2362],\n",
      "          [-1.1376,  1.0681]]]])\n",
      "tensor([[[[-1.2478, -1.2804],\n",
      "          [ 1.0480, -0.0234]],\n",
      "\n",
      "         [[ 0.2194,  0.7509],\n",
      "          [-0.2113,  0.3923]],\n",
      "\n",
      "         [[ 1.0334,  0.2553],\n",
      "          [ 0.7283, -1.0217]],\n",
      "\n",
      "         [[-1.5599, -0.2362],\n",
      "          [-1.1376,  1.0681]]]])\n",
      "torch.Size([1, 4, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(1,3,2,2)\n",
    "b = torch.randn(1,1,2,2)\n",
    "print(a)\n",
    "print(b)\n",
    "c = torch.cat((a,b),dim=1)\n",
    "print(c)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "fb40b41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0.],\n",
      "          [0., 0.]]]])\n",
      "torch.Size([2, 2])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1., 1.]])\n",
      "-------------------\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 1.]])\n",
      "tensor([[1., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 1.]])\n",
      "tensor([[1., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(1,1,2,2)\n",
    "print(a)\n",
    "b = torch.ones(1,2)\n",
    "print(a[0][0].size())\n",
    "print(a[0][0])\n",
    "print(b)\n",
    "tmp = torch.cat((a[0][0], b), dim=0)\n",
    "print(\"-------------------\")\n",
    "print(tmp)\n",
    "tmp = torch.cat((b, tmp), dim=0)\n",
    "print(tmp)\n",
    "a = torch.cat((b, a[0][0]), dim=0)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a48dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "    torch.onnx.export(model,               # model being run\n",
    "                    x,                         # model input (or a tuple for multiple inputs)\n",
    "                    onnxpath,   # where to save the model (can be a file or file-like object)\n",
    "                    export_params=True,        # store the trained parameter weights inside the model file\n",
    "                    opset_version=10,          # the ONNX version to export the model to\n",
    "                    do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                    input_names = ['input'],   # the model's input names\n",
    "                    output_names = ['output'], # the model's output names\n",
    "                    dynamic_axes={'input' : {0 : 'batch_size'},    # variable lenght axes\n",
    "                                  'output' : {0 : 'batch_size'}}\n",
    "                     )"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "æ— ",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
