{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "954126ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n",
      "1.6.0\n",
      "1.6.0\n",
      "torch.Size([1, 8, 240, 240])\n",
      "torch.Size([8, 240, 240])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from gym import wrappers\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional\n",
    "import glob\n",
    "# from base.rl.ppo import PPO\n",
    "\n",
    "pthfile = 'pth/ckpt.85.pth'\n",
    "onnxpath = 'onnx/ckpt.85.onnx'\n",
    "print(torch.__version__)\n",
    "print(onnx.__version__)\n",
    "print(onnxruntime.__version__)\n",
    "\n",
    "inputs = torch.randn(1, 8, 240, 240)\n",
    "\n",
    "map3 = torch.zeros(1, 240, 240)\n",
    "map3[0][20][20] = 1.\n",
    "inputs[0][3] = map3\n",
    "inputs[0][7] = map3\n",
    "x = inputs\n",
    "print(inputs.size())\n",
    "a = torch.squeeze(inputs,0)\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "944c4793",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "class Global_Actor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.actor = nn.Sequential(  # (8, G, G)\n",
    "            nn.Conv2d(8, 8, 3, padding=1),  # (8, G, G)\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 4, 3, padding=1),  # (4, G, G)\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 4, 5, padding=2),  # (4, G, G)\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 2, 5, padding=2),  # (2, G, G)\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2, 1, 5, padding=2),  # (1, G, G)\n",
    "            Flatten(),  # (G*G, )\n",
    "            nn.Sigmoid(),  # added for non-negative\n",
    "        )\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x2 = self.actor(inputs)\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d9404b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 240, 240])\n",
      "pth model output: tensor([[0.5101, 0.5092, 0.5040,  ..., 0.5096, 0.5036, 0.5043]],\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "torch.Size([1, 57600])\n",
      "onnx model output: [array([[0.48936778, 0.48698747, 0.48456502, ..., 0.4873169 , 0.49177426,\n",
      "        0.49493623]], dtype=float32)]\n",
      "tor_out:  (1, 57600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 20:00:53.119093694 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.0.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119117357 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.0.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119121845 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119125698 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.1.num_batches_tracked appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119129762 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.1.running_mean appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119133328 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.1.running_var appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119136952 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119140879 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.10.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119144483 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.10.num_batches_tracked appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119148070 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.10.running_mean appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119151666 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.10.running_var appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119156824 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.10.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119160471 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.12.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119164418 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.12.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119168002 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.3.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119171665 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.3.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119175258 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.4.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119178911 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.4.num_batches_tracked appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119182452 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.4.running_mean appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119186046 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.4.running_var appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119194118 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.4.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119197781 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.6.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119201334 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.6.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119205025 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.7.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119208653 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.7.num_batches_tracked appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119212354 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.7.running_mean appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119215902 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.7.running_var appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119219536 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.7.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119223198 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.9.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119227851 [W:onnxruntime:, graph.cc:1069 Graph] Initializer actor.9.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-13 20:00:53.119433645 [W:onnxruntime:, graph.cc:3093 CleanUnusedInitializers] Removing initializer 'actor.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\n",
      "2021-12-13 20:00:53.119440306 [W:onnxruntime:, graph.cc:3093 CleanUnusedInitializers] Removing initializer 'actor.10.num_batches_tracked'. It is not used by any node and should be removed from the model.\n",
      "2021-12-13 20:00:53.119444146 [W:onnxruntime:, graph.cc:3093 CleanUnusedInitializers] Removing initializer 'actor.7.num_batches_tracked'. It is not used by any node and should be removed from the model.\n",
      "2021-12-13 20:00:53.119447464 [W:onnxruntime:, graph.cc:3093 CleanUnusedInitializers] Removing initializer 'actor.4.num_batches_tracked'. It is not used by any node and should be removed from the model.\n"
     ]
    }
   ],
   "source": [
    "rl_net = Global_Actor()\n",
    "rl_net.actor.load_state_dict(torch.load(pthfile, map_location='cpu'),strict=False)\n",
    "rl_net.eval()\n",
    "\n",
    "x = inputs\n",
    "print(x.size())\n",
    "torch_out = rl_net(x)\n",
    "print(\"pth model output:\", torch_out)\n",
    "print(torch_out.shape)\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(onnxpath)\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_outs = ort_session.run(None, {ort_session.get_inputs()[0].name: x.cpu().numpy().astype(np.float32)})\n",
    "\n",
    "# compare ONNX Runtime and PyTorch results\n",
    "\n",
    "print(\"onnx model output:\", ort_outs)\n",
    "print('tor_out: ', torch_out.detach().numpy().shape)\n",
    "\n",
    "#np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "#print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77545c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cb7b24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
