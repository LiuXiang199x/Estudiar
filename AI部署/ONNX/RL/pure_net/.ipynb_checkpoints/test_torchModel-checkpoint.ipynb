{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d76d82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n",
      "1.6.0\n",
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from gym import wrappers\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional\n",
    "import glob\n",
    "# from base.rl.ppo import PPO\n",
    "\n",
    "pthfile = 'pth/ckpt.0.pth'\n",
    "onnxpath = 'onnx/ckpt.85.onnx'\n",
    "print(torch.__version__)\n",
    "print(onnx.__version__)\n",
    "print(onnxruntime.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "746913f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "class Global_Actor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.actor = nn.Sequential(  # (8, G, G)\n",
    "            nn.Conv2d(8, 8, 3, padding=1),  # (8, G, G)\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 4, 3, padding=1),  # (4, G, G)\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 4, 5, padding=2),  # (4, G, G)\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 2, 5, padding=2),  # (2, G, G)\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2, 1, 5, padding=2),  # (1, G, G)\n",
    "            Flatten(),  # (G*G, )\n",
    "            nn.Sigmoid(),  # added for non-negative\n",
    "        )\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x2 = self.actor(inputs)\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ca2e180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "see datas::::: 28924\n",
      "tensor([[0.4786, 0.4793, 0.4784,  ..., 0.4752, 0.4748, 0.4741]],\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "see datas::::: 28994\n",
      "tensor([[0.4782, 0.4788, 0.4793,  ..., 0.4751, 0.4742, 0.4751]],\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "see datas::::: 29100\n",
      "tensor([[0.4778, 0.4779, 0.4785,  ..., 0.4745, 0.4746, 0.4746]],\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "see datas::::: 29451\n",
      "tensor([[0.4780, 0.4779, 0.4776,  ..., 0.4753, 0.4748, 0.4740]],\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "see datas::::: 29076\n",
      "tensor([[0.4780, 0.4777, 0.4773,  ..., 0.4731, 0.4747, 0.4750]],\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "see datas::::: 29129\n",
      "tensor([[0.4784, 0.4781, 0.4781,  ..., 0.4744, 0.4765, 0.4743]],\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "see datas::::: 29104\n",
      "tensor([[0.4780, 0.4780, 0.4780,  ..., 0.4749, 0.4751, 0.4750]],\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "see datas::::: 28985\n",
      "tensor([[0.4785, 0.4789, 0.4776,  ..., 0.4754, 0.4753, 0.4745]],\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "see datas::::: 29184\n",
      "tensor([[0.4784, 0.4791, 0.4778,  ..., 0.4745, 0.4743, 0.4744]],\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "see datas::::: 29088\n",
      "tensor([[0.4784, 0.4791, 0.4782,  ..., 0.4755, 0.4753, 0.4742]],\n",
      "       grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "rl_net = Global_Actor()\n",
    "rl_net.actor.load_state_dict(torch.load(pthfile, map_location='cpu'),strict=False)\n",
    "rl_net.eval()\n",
    "\n",
    "for _ in range(10):\n",
    "    inputs = torch.zeros(1, 8, 240, 240)\n",
    "    for i in range(240):\n",
    "        for j in range(240):\n",
    "            if random.randint(0,100)>=50:\n",
    "                inputs[0][0][i][j] = 1\n",
    "                \n",
    "            if random.randint(0,100)>=50:\n",
    "                inputs[0][1][i][j] = 1\n",
    "\n",
    "            if random.randint(0,100)>=50:\n",
    "                inputs[0][3][i][j] = 1\n",
    "                \n",
    "            if random.randint(0,100)>=50:\n",
    "                inputs[0][4][i][j] = 1\n",
    "\n",
    "            if random.randint(0,100)>=50:\n",
    "                inputs[0][5][i][j] = 1\n",
    "                \n",
    "            if random.randint(0,100)>=50:\n",
    "                inputs[0][7][i][j] = 1\n",
    "\n",
    "    # print(\"see datas:::::\", np.sum(np.array(inputs[0][0])==1))\n",
    "    map3 = torch.zeros(1, 240, 240)\n",
    "    map3[0][random.randint(0,100)][random.randint(0,100)] = 1.\n",
    "    inputs[0][2] = map3\n",
    "    inputs[0][6] = map3\n",
    "    x = inputs\n",
    "    torch_out = rl_net(x)\n",
    "    print(torch_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35173fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
