{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "37166c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import gym\n",
    "import numpy\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from gym import wrappers\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional\n",
    "import glob\n",
    "# from base.rl.ppo import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "76da0d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n",
      "1.10.1\n",
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "pthfile = 'ckpt.test.pth'\n",
    "onnxpath = 'test_conv_pool.onnx'\n",
    "print(torch.__version__)\n",
    "print(onnx.__version__)\n",
    "print(onnxruntime.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4d679adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_map(h, x, crop_size, mode=\"bilinear\"):\n",
    "    \"\"\"\n",
    "    Crops a tensor h centered around location x with size crop_size\n",
    "\n",
    "    Inputs:\n",
    "        h - (bs, F, H, W)\n",
    "        x - (bs, 2) --- (x, y) locations\n",
    "        crop_size - scalar integer\n",
    "\n",
    "    Conventions for x:\n",
    "        The origin is at the top-left, X is rightward, and Y is downward.\n",
    "    \"\"\"\n",
    "\n",
    "    bs, _, H, W = h.size()\n",
    "    Hby2 = (H - 1) / 2 if H % 2 == 1 else H // 2\n",
    "    Wby2 = (W - 1) / 2 if W % 2 == 1 else W // 2\n",
    "    start = -(crop_size - 1) / 2 if crop_size % 2 == 1 else -(crop_size // 2)\n",
    "    end = start + crop_size - 1\n",
    "    x_grid = (\n",
    "        torch.arange(start, end + 1, step=1)\n",
    "        .unsqueeze(0)\n",
    "        .expand(crop_size, -1)\n",
    "        .contiguous()\n",
    "        .float()\n",
    "    )\n",
    "    y_grid = (\n",
    "        torch.arange(start, end + 1, step=1)\n",
    "        .unsqueeze(1)\n",
    "        .expand(-1, crop_size)\n",
    "        .contiguous()\n",
    "        .float()\n",
    "    )\n",
    "    center_grid = torch.stack([x_grid, y_grid], dim=2).to(\n",
    "        h.device\n",
    "    )  # (crop_size, crop_size, 2)\n",
    "\n",
    "    x_pos = x[:, 0] - Wby2  # (bs, )\n",
    "    y_pos = x[:, 1] - Hby2  # (bs, )\n",
    "\n",
    "    crop_grid = center_grid.unsqueeze(0).expand(\n",
    "        bs, -1, -1, -1\n",
    "    )  # (bs, crop_size, crop_size, 2)\n",
    "    crop_grid = crop_grid.contiguous()\n",
    "\n",
    "    # Convert the grid to (-1, 1) range\n",
    "    crop_grid[:, :, :, 0] = (\n",
    "        crop_grid[:, :, :, 0] + x_pos.unsqueeze(1).unsqueeze(2)\n",
    "    ) / Wby2\n",
    "    crop_grid[:, :, :, 1] = (\n",
    "        crop_grid[:, :, :, 1] + y_pos.unsqueeze(1).unsqueeze(2)\n",
    "    ) / Hby2\n",
    "\n",
    "    h_cropped = F.grid_sample(h, crop_grid, mode=mode)\n",
    "\n",
    "    return h_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f1116726",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "class Global_Actor(nn.Module):\n",
    "    def __init__(self, G):\n",
    "        super().__init__()\n",
    "        self.G = G\n",
    "        self.actor = nn.Sequential(  # (8, G, G)\n",
    "            nn.Conv2d(8, 8, 3, padding=1),  # (8, G, G)\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 4, 3, padding=1),  # (4, G, G)\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 4, 5, padding=2),  # (4, G, G)\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 2, 5, padding=2),  # (2, G, G)\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2, 1, 5, padding=2),  # (1, G, G)\n",
    "            # nn.BatchNorm2d(1),\n",
    "            Flatten(),  # (G*G, )\n",
    "            # nn.Sigmoid(),  # added for non-negative\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def _get_h12(self, inputs): # inputs needs to be a tensor, i.e., original inputs[\"map_at_t\"], (bs, 4, M, M), channel 3 means one-hot pose, channel 0~1 means global map\n",
    "        # x = inputs[\"pose_in_map_at_t\"]  # (bs,2)\n",
    "        # map_at_t (4, m, m)\n",
    "        x = torch.nonzero(inputs[0][3]==1)\n",
    "        h = inputs\n",
    "\n",
    "        h_1 = crop_map(h, x[:, :2], self.G)\n",
    "        h_2 = F.adaptive_max_pool2d(h, (self.G, self.G))\n",
    "\n",
    "        h_12 = torch.cat([h_1, h_2], dim=1)\n",
    "\n",
    "        return h_12\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x1 = self._get_h12(inputs)\n",
    "        x2 = self.actor(x1)\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8156500c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['0.weight', '0.bias', '1.weight', '1.bias', '1.running_mean', '1.running_var', '3.weight', '3.bias', '4.weight', '4.bias', '4.running_mean', '4.running_var', '6.weight', '6.bias', '7.weight', '7.bias', '7.running_mean', '7.running_var', '9.weight', '9.bias', '10.weight', '10.bias', '10.running_mean', '10.running_var', '12.weight', '12.bias'], unexpected_keys=['module.0.weight', 'module.0.bias', 'module.1.weight', 'module.1.bias', 'module.1.running_mean', 'module.1.running_var', 'module.1.num_batches_tracked', 'module.3.weight', 'module.3.bias', 'module.4.weight', 'module.4.bias', 'module.4.running_mean', 'module.4.running_var', 'module.4.num_batches_tracked', 'module.6.weight', 'module.6.bias', 'module.7.weight', 'module.7.bias', 'module.7.running_mean', 'module.7.running_var', 'module.7.num_batches_tracked', 'module.9.weight', 'module.9.bias', 'module.10.weight', 'module.10.bias', 'module.10.running_mean', 'module.10.running_var', 'module.10.num_batches_tracked', 'module.12.weight', 'module.12.bias'])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_net = Global_Actor(240)\n",
    "actor_net.actor.load_state_dict(torch.load(pthfile, map_location='cpu'),strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9d066423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    G=240\n",
    "    model = Global_Actor(240)\n",
    "    batch_size = 1\n",
    "    input_shape = (8, G, G)\n",
    "    \n",
    "    # Initialize model with the pretrained weights\n",
    "    map_location = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "    loaded_model = torch.load(pthfile, map_location=map_location)\n",
    "    model.load_state_dict(loaded_model, strict=False)\n",
    "    \n",
    "    # set the model to inference mode\n",
    "    model.eval()\n",
    "    \n",
    "    # data type nchw\n",
    "    x = torch.rand(batch_size, *input_shape)\n",
    "    input_names = ['input']\n",
    "    output_names = ['output']\n",
    "    # # Export the model\n",
    "    torch.onnx.export(model,               # model being run\n",
    "                    x,                         # model input (or a tuple for multiple inputs)\n",
    "                    onnxpath,   # where to save the model (can be a file or file-like object)\n",
    "                    export_params=True,        # store the trained parameter weights inside the model file\n",
    "                    opset_version=10,          # the ONNX version to export the model to\n",
    "                    do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                    input_names = ['input'],   # the model's input names\n",
    "                    output_names = ['output'], # the model's output names\n",
    "                    dynamic_axes={'input' : {0 : 'batch_size'},    # variable lenght axes\n",
    "                                  'output' : {0 : 'batch_size'}}\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4c1e9656",
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3532621f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "tensor([[0.3203, 0.6363]])\n",
      "tensor([[1., 1.]])\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn((1,2))\n",
    "print(a.size())\n",
    "print(a)\n",
    "b = torch.ones(1,2)\n",
    "print(b)\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26a51963",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.randn(4,6,6)\n",
    "# print(c)\n",
    "# print(c[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da5ab889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor([[1,2,3],[4,5,6]])\n",
    "target = 2\n",
    "a = torch.nonzero(data==target)\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb37ef22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
