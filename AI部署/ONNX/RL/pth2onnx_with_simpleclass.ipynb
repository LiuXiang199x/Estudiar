{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a982c402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import gym\n",
    "import numpy\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from gym import wrappers\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional\n",
    "import glob\n",
    "# from base.rl.ppo import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c594e0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n",
      "1.10.1\n",
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "pthfile = 'ckpt.test.pth'\n",
    "onnxpath = 'test_simpleclass.onnx'\n",
    "print(torch.__version__)\n",
    "print(onnx.__version__)\n",
    "print(onnxruntime.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7a9c3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "class Global_Actor(nn.Module):\n",
    "    def __init__(self, G):\n",
    "        super().__init__()\n",
    "        self.G = G\n",
    "        self.actor = nn.Sequential(  # (8, G, G)\n",
    "            nn.Conv2d(8, 8, 3, padding=1),  # (8, G, G)\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 4, 3, padding=1),  # (4, G, G)\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 4, 5, padding=2),  # (4, G, G)\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 2, 5, padding=2),  # (2, G, G)\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2, 1, 5, padding=2),  # (1, G, G)\n",
    "            # nn.BatchNorm2d(1),\n",
    "            Flatten(),  # (G*G, )\n",
    "            # nn.Sigmoid(),  # added for non-negative\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4577790",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_net = Global_Actor(240).actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7156f25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['0.weight', '0.bias', '1.weight', '1.bias', '1.running_mean', '1.running_var', '3.weight', '3.bias', '4.weight', '4.bias', '4.running_mean', '4.running_var', '6.weight', '6.bias', '7.weight', '7.bias', '7.running_mean', '7.running_var', '9.weight', '9.bias', '10.weight', '10.bias', '10.running_mean', '10.running_var', '12.weight', '12.bias'], unexpected_keys=['module.0.weight', 'module.0.bias', 'module.1.weight', 'module.1.bias', 'module.1.running_mean', 'module.1.running_var', 'module.1.num_batches_tracked', 'module.3.weight', 'module.3.bias', 'module.4.weight', 'module.4.bias', 'module.4.running_mean', 'module.4.running_var', 'module.4.num_batches_tracked', 'module.6.weight', 'module.6.bias', 'module.7.weight', 'module.7.bias', 'module.7.running_mean', 'module.7.running_var', 'module.7.num_batches_tracked', 'module.9.weight', 'module.9.bias', 'module.10.weight', 'module.10.bias', 'module.10.running_mean', 'module.10.running_var', 'module.10.num_batches_tracked', 'module.12.weight', 'module.12.bias'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_net.load_state_dict(torch.load(pthfile, map_location='cpu'),strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eaaa0696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    G=240\n",
    "    model = Global_Actor(240).actor\n",
    "    batch_size = 1\n",
    "    input_shape = (8, G, G)\n",
    "    \n",
    "    # Initialize model with the pretrained weights\n",
    "    map_location = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "    loaded_model = torch.load(pthfile, map_location=map_location)\n",
    "    model.load_state_dict(loaded_model, strict=False)\n",
    "    \n",
    "    # set the model to inference mode\n",
    "    model.eval()\n",
    "    \n",
    "    # data type nchw\n",
    "    x = torch.rand(batch_size, *input_shape)\n",
    "    input_names = ['input']\n",
    "    output_names = ['output']\n",
    "    # # Export the model\n",
    "    torch.onnx.export(model,               # model being run\n",
    "                    x,                         # model input (or a tuple for multiple inputs)\n",
    "                    onnxpath,   # where to save the model (can be a file or file-like object)\n",
    "                    export_params=True,        # store the trained parameter weights inside the model file\n",
    "                    opset_version=10,          # the ONNX version to export the model to\n",
    "                    do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                    input_names = ['input'],   # the model's input names\n",
    "                    output_names = ['output'], # the model's output names\n",
    "                    dynamic_axes={'input' : {0 : 'batch_size'},    # variable lenght axes\n",
    "                                  'output' : {0 : 'batch_size'}}\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95b13c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63226fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
