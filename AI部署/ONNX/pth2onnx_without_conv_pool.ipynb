{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "79eb9f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import torch\n",
    "import torch.onnx\n",
    "import onnx\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "# from utils.dataset import BasicDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "61343e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n",
      "1.10.1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "pthfile = 'ckpt.test.pth'\n",
    "onnxpath = 'test.onnx'\n",
    "print(torch.__version__)\n",
    "print(onnx.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3b3d9a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "actor = nn.Sequential(  # (8, G, G)\n",
    "            nn.Conv2d(8, 8, 3, padding=1),  # (8, G, G)\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 4, 3, padding=1),  # (4, G, G)\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 4, 5, padding=2),  # (4, G, G)\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 2, 5, padding=2),  # (2, G, G)\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2, 1, 5, padding=2),  # (1, G, G)\n",
    "            #nn.BatchNorm2d(1),\n",
    "            Flatten(),  # (G*G, )\n",
    "            #nn.Sigmoid(),  # added for non-negative\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "664d583d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['0.weight', '0.bias', '1.weight', '1.bias', '1.running_mean', '1.running_var', '3.weight', '3.bias', '4.weight', '4.bias', '4.running_mean', '4.running_var', '6.weight', '6.bias', '7.weight', '7.bias', '7.running_mean', '7.running_var', '9.weight', '9.bias', '10.weight', '10.bias', '10.running_mean', '10.running_var', '12.weight', '12.bias'], unexpected_keys=['module.0.weight', 'module.0.bias', 'module.1.weight', 'module.1.bias', 'module.1.running_mean', 'module.1.running_var', 'module.1.num_batches_tracked', 'module.3.weight', 'module.3.bias', 'module.4.weight', 'module.4.bias', 'module.4.running_mean', 'module.4.running_var', 'module.4.num_batches_tracked', 'module.6.weight', 'module.6.bias', 'module.7.weight', 'module.7.bias', 'module.7.running_mean', 'module.7.running_var', 'module.7.num_batches_tracked', 'module.9.weight', 'module.9.bias', 'module.10.weight', 'module.10.bias', 'module.10.running_mean', 'module.10.running_var', 'module.10.num_batches_tracked', 'module.12.weight', 'module.12.bias'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map_location = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "actor.load_state_dict(torch.load(pthfile, map_location='cpu'),strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4c04cfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    G=240\n",
    "    model = actor\n",
    "    batch_size = 1\n",
    "    input_shape = (8, G, G)\n",
    "    \n",
    "    # Initialize model with the pretrained weights\n",
    "    map_location = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "    loaded_model = torch.load(pthfile, map_location=map_location)\n",
    "    model.load_state_dict(loaded_model, strict=False)\n",
    "    \n",
    "    # set the model to inference mode\n",
    "    model.eval()\n",
    "    \n",
    "    # data type nchw\n",
    "    x = torch.rand(batch_size, *input_shape)\n",
    "    input_names = ['input']\n",
    "    output_names = ['output']\n",
    "    # # Export the model\n",
    "    torch.onnx.export(model,               # model being run\n",
    "                    x,                         # model input (or a tuple for multiple inputs)\n",
    "                    onnxpath,   # where to save the model (can be a file or file-like object)\n",
    "                    export_params=True,        # store the trained parameter weights inside the model file\n",
    "                    opset_version=10,          # the ONNX version to export the model to\n",
    "                    do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                    input_names = ['input'],   # the model's input names\n",
    "                    output_names = ['output'], # the model's output names\n",
    "                    dynamic_axes={'input' : {0 : 'batch_size'},    # variable lenght axes\n",
    "                                  'output' : {0 : 'batch_size'}}\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f5a41419",
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e5605ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.1'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "注意，模型的输入大小和测试的输入数据一致；\n",
    "注意，在导出模型之前，请先调用torch_model.eval()或torch_model.train(False)，以将模型转换为推理模式，这一点很重要。 这是必需的，因为像dropout或batchnorm这样的运算符在推断和训练模式下的行为会有所不同。\n",
    "注意，除非指定为动态轴，否则输入尺寸将在导出的 ONNX 图中固定为所有输入尺寸。\n",
    "在此示例中，我们使用输入batch_size=1导出模型，但随后在torch.onnx.export()的dynamic_axes参数中将第一维指定为动态。 因此，导出的模型将接受大小为[batch_size,3, 640, 959]的输入，其中batch_size可以是可变的。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2296b674",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
