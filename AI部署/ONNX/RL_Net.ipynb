{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdb804ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import gym\n",
    "import numpy\n",
    "from gym import wrappers\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional\n",
    "import glob\n",
    "# from base.rl.ppo import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d33d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalPolicy(nn.Module):\n",
    "    def __init__(self, G=240, use_data_parallel=False, gpu_ids=[]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.G = G\n",
    "\n",
    "        self.actor = nn.Sequential(  # (8, G, G)\n",
    "            nn.Conv2d(8, 8, 3, padding=1),  # (8, G, G)\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 4, 3, padding=1),  # (4, G, G)\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 4, 5, padding=2),  # (4, G, G)\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 2, 5, padding=2),  # (2, G, G)\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2, 1, 5, padding=2),  # (1, G, G)\n",
    "            Flatten(),  # (G*G, )\n",
    "            nn.Sigmoid(), # frontier_mask\n",
    "        )\n",
    "\n",
    "        self.critic = nn.Sequential(  # (8, G, G)\n",
    "            nn.Conv2d(8, 8, 3, padding=1),  # (8, G, G)\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 4, 3, padding=1),  # (4, G, G)\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 4, 5, padding=2),  # (4, G, G)\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 2, 5, padding=2),  # (2, G, G)\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2, 1, 5, padding=2),  # (1, G, G)\n",
    "            Flatten(),\n",
    "            nn.Linear(self.G * self.G, 1),\n",
    "        )\n",
    "\n",
    "        if use_data_parallel:\n",
    "            self.actor = nn.DataParallel(\n",
    "                self.actor, device_ids=gpu_ids, output_device=gpu_ids[0],\n",
    "            )\n",
    "            self.critic = nn.DataParallel(\n",
    "                self.critic, device_ids=gpu_ids, output_device=gpu_ids[0],\n",
    "            )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _get_h12(self, inputs):\n",
    "        x = inputs[\"pose_in_map_at_t\"]\n",
    "        h = inputs[\"map_at_t\"]\n",
    "\n",
    "        h_1 = crop_map(h, x[:, :2], self.G)\n",
    "        h_2 = F.adaptive_max_pool2d(h, (self.G, self.G))\n",
    "\n",
    "        h_12 = torch.cat([h_1, h_2], dim=1)\n",
    "\n",
    "        return h_12\n",
    "\n",
    "    def act(self, inputs, rnn_hxs, prev_actions, masks, deterministic=False):\n",
    "        \"\"\"\n",
    "        Note: inputs['pose_in_map_at_t'] must obey the following conventions:\n",
    "              origin at top-left, downward Y and rightward X in the map coordinate system.\n",
    "        \"\"\"\n",
    "        M = inputs[\"map_at_t\"].shape[2]\n",
    "        h_12 = self._get_h12(inputs)\n",
    "        '''\n",
    "        action_logits = self.actor(h_12)\n",
    "        dist = FixedCategorical(logits=action_logits)\n",
    "        value = self.critic(h_12)\n",
    "\n",
    "        if deterministic:\n",
    "            action = dist.mode()\n",
    "        else:\n",
    "            action = dist.sample()\n",
    "\n",
    "        action_log_probs = dist.log_probs(action)\n",
    "        '''\n",
    "        #'''  # frontier_mask\n",
    "        action_logits = torch.clamp(self.actor(h_12), min=1e-4, max=1 - 1e-4)\n",
    "        value = self.critic(h_12)\n",
    "        action_mask = inputs[\"frontier_mask\"]\n",
    "        action_probs_mask = torch.where(action_mask == 1, action_logits, torch.ones_like(action_logits)*1e-7)\n",
    "        dist_2 = FixedCategorical(probs=action_probs_mask, validate_args=False)\n",
    "        if deterministic:\n",
    "            action = dist_2.mode()\n",
    "        else:\n",
    "            action = dist_2.sample()\n",
    "        action_log_probs = dist_2.log_probs(action)\n",
    "        #''' # frontier_mask\n",
    "        return value, action, action_log_probs, rnn_hxs\n",
    "\n",
    "    def get_value(self, inputs, rnn_hxs, prev_actions, masks):\n",
    "        h_12 = self._get_h12(inputs)\n",
    "        value = self.critic(h_12)\n",
    "        return value\n",
    "\n",
    "    def evaluate_actions(self, inputs, rnn_hxs, prev_actions, masks, action):\n",
    "        h_12 = self._get_h12(inputs)\n",
    "        '''\n",
    "        action_logits = self.actor(h_12)\n",
    "        dist = FixedCategorical(logits=action_logits)\n",
    "        value = self.critic(h_12)\n",
    "\n",
    "        action_log_probs = dist.log_probs(action)\n",
    "\n",
    "        dist_entropy = dist.entropy().mean()\n",
    "\n",
    "        return value, action_log_probs, dist_entropy, rnn_hxs\n",
    "        '''\n",
    "\n",
    "        #'''  # frontier_mask\n",
    "        action_logits = torch.clamp(self.actor(h_12), min=1e-4, max=1-1e-4)\n",
    "        value = self.critic(h_12)\n",
    "        action_mask = inputs[\"frontier_mask\"]\n",
    "        action_probs_mask = torch.where(action_mask == 1, action_logits, torch.ones_like(action_logits)*1e-7)\n",
    "        dist_2 = FixedCategorical(probs=action_probs_mask, validate_args=False)\n",
    "        action_log_probs = dist_2.log_probs(action)\n",
    "\n",
    "        dist_entropy = dist_2.entropy().mean()\n",
    "        return value, action_log_probs, dist_entropy, rnn_hxs\n",
    "        #'''  # frontier_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4c09b77",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'map_size_for_g_policy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7046/1853296456.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglobal_policy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlobalPolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_size_for_g_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_data_parallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_policy_gpu_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m global_agent = PPO(\n\u001b[1;32m      3\u001b[0m     \u001b[0mactor_critic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclip_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mppo_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mppo_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'map_size_for_g_policy' is not defined"
     ]
    }
   ],
   "source": [
    "global_policy = GlobalPolicy(G=map_size_for_g_policy, use_data_parallel=True, gpu_ids=global_policy_gpu_ids)\n",
    "global_agent = PPO(\n",
    "    actor_critic=global_policy,\n",
    "    clip_param=clip_param,\n",
    "    ppo_epoch=ppo_epoch,\n",
    "    num_mini_batch=num_mini_batch,\n",
    "    value_loss_coef=value_loss_coef,\n",
    "    entropy_coef=entropy_coef,\n",
    "    lr=lr,\n",
    "    eps=eps,\n",
    "    max_grad_norm=max_grad_norm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4564a33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
