{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "069a8d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n",
      "1.6.0\n",
      "1.6.0\n",
      "torch.Size([1, 3, 1200, 1200])\n",
      "torch.Size([3, 1200, 1200])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from gym import wrappers\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional\n",
    "import glob\n",
    "# from base.rl.ppo import PPO\n",
    "\n",
    "pthfile = 'pth/net_params.pth'\n",
    "onnxpath = 'onnx/net.onnx'\n",
    "print(torch.__version__)\n",
    "print(onnx.__version__)\n",
    "print(onnxruntime.__version__)\n",
    "\n",
    "inputs = torch.randn(1, 3, 1200, 1200)\n",
    "\n",
    "map3 = torch.zeros(1, 1200, 1200)\n",
    "map3[0][340][220] = 1.\n",
    "inputs[0][2] = map3\n",
    "x = inputs\n",
    "print(inputs.size())\n",
    "a = torch.squeeze(inputs,0)\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaa2b8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "class Global_Actor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.actor = nn.Sequential(  # (3, 1200, 1200)\n",
    "            nn.Conv2d(3, 8, 5, padding=2),  # (8, 1200, 1200)\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # (8, 600, 600)\n",
    "            nn.Conv2d(8, 16, 3, padding=1),  # (16, 600, 600)\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # (16, 300, 300)\n",
    "            nn.Conv2d(16, 32, 5, padding=2),  # (32, 300, 300)\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # (64, 150, 150)\n",
    "            nn.Conv2d(32, 64, 3, padding=1),  # (64, 150, 150)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 1, 1, padding=0),  # (1, 150, 150)\n",
    "            Flatten(),  # (G*G, )\n",
    "            # nn.Sigmoid(),  # frontier_mask\n",
    "        )\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x2 = self.actor(inputs)\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24a9b08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1200, 1200])\n",
      "pth model output: tensor([[ 0.0263,  0.0343,  0.0242,  ..., -0.0225, -0.0219, -0.0073]],\n",
      "       grad_fn=<ViewBackward>)\n",
      "torch.Size([1, 22500])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 11:11:11.625055269 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 1 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625254455 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 10 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625263966 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 11 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625270437 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 12 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625276780 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 13 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625282954 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 14 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625289516 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 15 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625295832 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 16 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625301988 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 17 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625308147 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 18 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625314512 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 19 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625322123 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 2 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625328745 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 20 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625335788 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 21 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625342337 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 22 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625348741 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 23 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625355110 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 24 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625361269 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 25 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625367656 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 26 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625373941 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 27 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625381167 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 28 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625387650 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 29 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625394068 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 3 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625400248 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 30 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625406493 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 4 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625412639 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 5 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625419055 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 6 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625425355 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 7 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625431711 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 8 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.625439765 [W:onnxruntime:, graph.cc:1069 Graph] Initializer 9 appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2022-01-05 11:11:11.626226574 [W:onnxruntime:, graph.cc:3093 CleanUnusedInitializers] Removing initializer '28'. It is not used by any node and should be removed from the model.\n",
      "2022-01-05 11:11:11.626239921 [W:onnxruntime:, graph.cc:3093 CleanUnusedInitializers] Removing initializer '14'. It is not used by any node and should be removed from the model.\n",
      "2022-01-05 11:11:11.626246518 [W:onnxruntime:, graph.cc:3093 CleanUnusedInitializers] Removing initializer '7'. It is not used by any node and should be removed from the model.\n",
      "2022-01-05 11:11:11.626252531 [W:onnxruntime:, graph.cc:3093 CleanUnusedInitializers] Removing initializer '21'. It is not used by any node and should be removed from the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onnx model output: [array([[ 0.026309  ,  0.03428867,  0.02417477, ..., -0.02254308,\n",
      "        -0.02188145, -0.00730101]], dtype=float32)]\n",
      "tor_out:  (1, 22500)\n"
     ]
    }
   ],
   "source": [
    "rl_net = Global_Actor()\n",
    "rl_net.actor.load_state_dict(torch.load(pthfile, map_location='cpu'),strict=False)\n",
    "rl_net.eval()\n",
    "\n",
    "x = inputs\n",
    "print(x.size())\n",
    "torch_out = rl_net(x)\n",
    "print(\"pth model output:\", torch_out)\n",
    "print(torch_out.shape)\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(onnxpath)\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_outs = ort_session.run(None, {ort_session.get_inputs()[0].name: x.cpu().numpy().astype(np.float32)})\n",
    "\n",
    "# compare ONNX Runtime and PyTorch results\n",
    "\n",
    "print(\"onnx model output:\", ort_outs)\n",
    "print('tor_out: ', torch_out.detach().numpy().shape)\n",
    "\n",
    "#np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "#print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd369d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14400"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd58dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
