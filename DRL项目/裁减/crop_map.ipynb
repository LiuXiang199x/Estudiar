{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c4e1e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce7d0d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 3]])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(1, 4, 481, 481)\n",
    "inputs[0][3][3][3] = 1\n",
    "x = torch.nonzero(inputs[0][3]==1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d153352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_map(h, crop_size):\n",
    "    \n",
    "    bs, ch, H, W = h.size()\n",
    "    print(h.size())\n",
    "    \n",
    "    map_tmp = torch.zeros(1, 4, H+crop_size, W+crop_size)\n",
    "    map_c1 = torch.ones(H+crop_size, W+crop_size)\n",
    "    map_tmp[0][0] = map_c1\n",
    "   \n",
    "    for i in range(ch):\n",
    "        map_tmp[0][i][crop_size//2:crop_size//2+H, crop_size//2:crop_size//2+W] = h[0][i]\n",
    "    \n",
    "    x_pos = torch.nonzero(map_tmp[0][3]==1)[:][:,0][0]\n",
    "    y_pos = torch.nonzero(map_tmp[0][3]==1)[:][:,1][0]\n",
    "    print(\"x_pos:\", x_pos)\n",
    "    # print(map_tmp)\n",
    "    print(\"x_pos:{}, y_pos:{}\".format(x_pos,y_pos))\n",
    "    print(type(y_pos))\n",
    "    # print(map_tmp.size())\n",
    "    # print(torch.nonzero(map_tmp[0][3]==1))\n",
    "    \n",
    "    output = torch.randn(1, 4, crop_size, crop_size)\n",
    "    print(\"x_pos-crop_size//2:x_pos+crop_size//2:\", x_pos-crop_size//2)\n",
    "    for i in range(ch):\n",
    "        if crop_size%2 == 0:\n",
    "            output[0][i] = map_tmp[0][i][x_pos-crop_size//2:x_pos+crop_size//2, y_pos-crop_size//2:y_pos+crop_size//2]\n",
    "        else:\n",
    "            output[0][i] = map_tmp[0][i][x_pos-crop_size//2:x_pos+crop_size//2+1, y_pos-crop_size//2:y_pos+crop_size//2+1]\n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb5e2e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0]])\n",
      "tensor([[[[ 1.0152,  0.9502, -0.5721,  0.9429,  1.8131,  0.3201],\n",
      "          [ 0.0832, -1.2330,  1.8328, -1.6603,  0.4157, -1.7857],\n",
      "          [-0.4274, -0.5448, -0.3152,  0.2619, -1.2369,  0.1625],\n",
      "          [ 0.2658,  0.6412, -0.5335, -0.3450,  0.7805, -0.8096],\n",
      "          [ 0.9514,  1.9749,  0.3116, -0.5790, -0.3669,  1.4854],\n",
      "          [-0.3704,  0.3333, -0.6485,  0.5441,  1.4294, -0.5217]],\n",
      "\n",
      "         [[ 1.9797, -1.0624,  0.4209, -1.8423,  0.6186,  0.0981],\n",
      "          [-1.9849, -0.6857,  0.4291,  1.7524, -0.4056,  1.6470],\n",
      "          [ 1.4825, -0.1919, -0.2294, -0.3798,  0.4144, -0.7280],\n",
      "          [ 0.5650, -2.0395, -1.2648,  0.6714,  0.2187,  0.3129],\n",
      "          [-1.3115,  2.0814, -0.6310, -0.3745,  0.7805, -0.2673],\n",
      "          [-0.2774, -0.0758, -0.2359,  0.5439, -1.0801, -2.1026]],\n",
      "\n",
      "         [[-0.9457, -0.4126,  0.0227,  0.2388, -1.3501, -0.5433],\n",
      "          [-0.3973,  0.7479,  1.1237, -0.3419, -0.6054, -0.2797],\n",
      "          [-2.1882,  0.4362, -0.4509, -0.8906, -0.1936,  1.5156],\n",
      "          [ 1.4845,  1.6408, -0.0228,  0.2368, -0.9565,  0.2227],\n",
      "          [-0.1958,  0.0545,  1.0951,  0.3548, -0.7818,  0.8266],\n",
      "          [-0.3373, -0.9311, -0.3857, -1.1927, -2.1400,  0.5316]],\n",
      "\n",
      "         [[ 1.0000,  0.1328,  0.5118,  1.2293,  0.8421, -0.9860],\n",
      "          [ 0.7451, -1.5302, -0.6445,  0.8442,  1.2045, -0.9692],\n",
      "          [-0.2919,  1.8675, -0.0840,  1.0943,  1.3836,  0.9182],\n",
      "          [ 1.3612,  0.1747,  2.3434, -0.9774, -0.1959,  0.1451],\n",
      "          [ 0.5993, -0.4383, -0.8883,  0.2739,  0.5117, -1.5810],\n",
      "          [-1.1305, -0.7083, -0.0919, -0.4115,  1.1431,  1.1644]]]])\n",
      "torch.Size([1, 4, 6, 6])\n",
      "x_pos: tensor(1)\n",
      "x_pos:1, y_pos:1\n",
      "<class 'torch.Tensor'>\n",
      "x_pos-crop_size//2:x_pos+crop_size//2: tensor(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.0000,  1.0000],\n",
       "          [ 1.0000,  1.0152]],\n",
       "\n",
       "         [[ 0.0000,  0.0000],\n",
       "          [ 0.0000,  1.9797]],\n",
       "\n",
       "         [[ 0.0000,  0.0000],\n",
       "          [ 0.0000, -0.9457]],\n",
       "\n",
       "         [[ 0.0000,  0.0000],\n",
       "          [ 0.0000,  1.0000]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs2 = torch.randn(1, 4, 6, 6)\n",
    "\n",
    "inputs2[0][3][0][0] = 1\n",
    "x = torch.nonzero(inputs2[0][3]==1)\n",
    "print(x)\n",
    "print(inputs2)\n",
    "# print(inputs2)\n",
    "crop_map(inputs2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1037f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 3]])\n",
      "torch.Size([1, 2])\n",
      "tensor([[[2],\n",
      "         [3]]])\n",
      "tensor([[2, 3]])\n",
      "tensor(5)\n",
      "tensor(1.8849)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[2,3]])\n",
    "b = torch.randn(10,10)\n",
    "print(a)\n",
    "print(a.size())\n",
    "print(torch.unsqueeze(a, 2))\n",
    "print(a)\n",
    "print(a[:][:,0][0] + a[:][:,1][0])\n",
    "print(b[a[:][:,0][0]][a[:][:,1][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "58a9c9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.0409)\n",
      "tensor([[-0.2100,  0.5048,  0.1150, -1.3764, -0.0068],\n",
      "        [-0.1414,  0.7513,  0.5066, -0.5157, -1.1068],\n",
      "        [-1.2784,  1.2264, -0.4960,  2.4908,  0.5956],\n",
      "        [-0.8810,  0.1898,  1.3371, -1.0409, -1.0964],\n",
      "        [ 0.9607, -0.9174, -0.6322,  0.3216,  0.6967]])\n",
      "---------\n",
      "tensor([[-0.4960,  2.4908,  0.5956],\n",
      "        [ 1.3371, -1.0409, -1.0964],\n",
      "        [-0.6322,  0.3216,  0.6967]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn((5,5))\n",
    "print(a[3][3])\n",
    "print(a)\n",
    "print(\"---\"*3)\n",
    "print(a[3-1:3+2, 3-1:3+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "39f0d497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "print(a[0])\n",
    "print(a[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1f22e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(1)\n",
    "print(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a724889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
