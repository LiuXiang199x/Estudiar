{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c78a5018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n",
      "1.6.0\n",
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import gym\n",
    "import numpy\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from gym import wrappers\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional\n",
    "import glob\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "#import caffe2.python.onnx.backend as onnx_caffe2\n",
    "\n",
    "# import geffnet\n",
    "# from base.rl.ppo import PPO\n",
    "\n",
    "pthfile = 'pth/ckpt.20.pth'\n",
    "onnxpath = 'onnx/ckpt.20.onnx'\n",
    "print(torch.__version__)\n",
    "print(onnx.__version__)\n",
    "print(onnxruntime.__version__)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "class Global_Actor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.actor = nn.Sequential(  # (8, G, G)\n",
    "            nn.Conv2d(8, 8, 3, padding=1),  # (8, G, G)\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 4, 3, padding=1),  # (4, G, G)\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 4, 5, padding=2),  # (4, G, G)\n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 2, 5, padding=2),  # (2, G, G)\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2, 1, 5, padding=2),  # (1, G, G)\n",
    "            Flatten(),  # (G*G, )\n",
    "            nn.Sigmoid(),  # added for non-negative\n",
    "        )\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x2 = self.actor(inputs)\n",
    "        return x2\n",
    "    \n",
    "def test():\n",
    "    M = 240\n",
    "    batch_size = 1\n",
    "    input_shape = (8, M, M)\n",
    "    \n",
    "    # Initialize model with the pretrained weights\n",
    "    # map_location = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "    # loaded_model = torch.load(pthfile, map_location=\"cpu\")\n",
    "    # model.actor.load_state_dict(loaded_model, strict=False)\n",
    "    \n",
    "    model = Global_Actor()\n",
    "    model.actor.load_state_dict(torch.load(pthfile, map_location='cpu'),strict=False)\n",
    "    # set the model to inference mode\n",
    "    model.eval()\n",
    "    \n",
    "    inputs = torch.randn(1, 8, 240, 240)\n",
    "    map3 = torch.zeros(1, 240, 240)\n",
    "    map3[0][20][20] = 1.\n",
    "    inputs[0][3] = map3\n",
    "    inputs[0][7] = map3\n",
    "    x = inputs\n",
    "    # data type nchw\n",
    "    # x = torch.rand(batch_size, *input_shape)\n",
    "    input_names = [\"input0\"]\n",
    "    output_names = [\"output0\"]\n",
    "    optional_args = dict(keep_initializers_as_inputs=True)  # pytorch 1.3 needs this for export to succeed\n",
    "\n",
    "    try:\n",
    "        torch_out = torch.onnx._export(\n",
    "            model, x, onnxpath, export_params=True, verbose=False,\n",
    "            input_names=input_names, output_names=output_names, **optional_args,\n",
    "            opset_version=10)\n",
    "    except TypeError:\n",
    "        # fallback to no keep_initializers arg for pytorch < 1.3\n",
    "        torch_out = torch.onnx._export(\n",
    "            model, x, onnxpath, export_params=True, verbose=False,\n",
    "            input_names=input_names, output_names=output_names, opset_version=10)\n",
    "    '''\n",
    "    # # Export the model\n",
    "    torch.onnx.export(model, x, \n",
    "                      onnxpath, \n",
    "                      opset_version=10)\n",
    "                      #keep_initializers_as_inputs=True, \n",
    "                      # verbose=True\n",
    "     '''\n",
    "    print(\"=============Successful==========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18a7ca00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============Successful==========\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49a066c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
