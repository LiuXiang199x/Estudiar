{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f3b4bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import onnx\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f12398ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        print(\"after 1 conv:\", x.size())  # [1, 6, 28, 28]\n",
    "\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        print(\"after 1 conv:\", x.size())  # [1, 6, 28, 28]\n",
    "\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    # num_flat_features：计算张量x的总特征量（把每个数字都看出是一个特征，即特征总量）\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension(批大小维度)\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5f15a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "第0个参数形状为torch.Size([6, 1, 5, 5])\n",
      "第1个参数形状为torch.Size([6])\n",
      "第2个参数形状为torch.Size([16, 6, 5, 5])\n",
      "第3个参数形状为torch.Size([16])\n",
      "第4个参数形状为torch.Size([120, 400])\n",
      "第5个参数形状为torch.Size([120])\n",
      "第6个参数形状为torch.Size([84, 120])\n",
      "第7个参数形状为torch.Size([84])\n",
      "第8个参数形状为torch.Size([10, 84])\n",
      "第9个参数形状为torch.Size([10])\n",
      "tensor([[[[-0.0946, -0.4331,  0.1049,  ..., -1.7064, -0.4263,  0.1183],\n",
      "          [-2.1867, -0.0615,  1.0661,  ..., -1.1888,  0.2416,  1.0151],\n",
      "          [-1.0415,  0.1843, -0.1180,  ...,  0.9071, -0.6675, -0.6326],\n",
      "          ...,\n",
      "          [ 0.6196, -2.0734,  0.0409,  ..., -0.5851, -0.8084, -0.9392],\n",
      "          [ 2.9923, -0.8401, -2.0703,  ..., -0.9866, -2.2073, -0.2497],\n",
      "          [-0.1664,  0.5513, -0.3112,  ...,  0.8007, -0.6792,  0.8023]]]])\n",
      "conv1输出的形状： torch.Size([1, 6, 28, 28])\n",
      "after 1 conv: torch.Size([1, 6, 14, 14])\n",
      "after 1 conv: torch.Size([1, 16, 5, 5])\n",
      "输出层形状 torch.Size([1, 10])\n",
      "输出层结果： tensor([[-0.0773, -0.0849,  0.0981, -0.1587,  0.0063, -0.0250,  0.0210,  0.0354,\n",
      "         -0.0395,  0.1735]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(type(params[0]))\n",
    "for i in range(10):\n",
    "    print(\"第{}个参数形状为{}\".format(i,params[i].size()))\n",
    "input = torch.randn(1, 1, 32, 32)\n",
    "print(input)\n",
    "print('conv1输出的形状：',net.conv1(input).size()) # conv1输出的形状\n",
    "\n",
    "out = net(input)\n",
    "print('输出层形状',out.size())\n",
    "print('输出层结果：',out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab299451",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Net:\n\tMissing key(s) in state_dict: \"conv2.weight\", \"conv2.bias\". \n\tUnexpected key(s) in state_dict: \"net.0.weight\", \"net.0.bias\", \"net.1.weight\", \"net.1.bias\", \"net.1.running_mean\", \"net.1.running_var\", \"net.1.num_batches_tracked\", \"net.4.weight\", \"net.4.bias\", \"net.5.weight\", \"net.5.bias\", \"net.5.running_mean\", \"net.5.running_var\", \"net.5.num_batches_tracked\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50231/1003714524.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'net_params.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 830\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Net:\n\tMissing key(s) in state_dict: \"conv2.weight\", \"conv2.bias\". \n\tUnexpected key(s) in state_dict: \"net.0.weight\", \"net.0.bias\", \"net.1.weight\", \"net.1.bias\", \"net.1.running_mean\", \"net.1.running_var\", \"net.1.num_batches_tracked\", \"net.4.weight\", \"net.4.bias\", \"net.5.weight\", \"net.5.bias\", \"net.5.running_mean\", \"net.5.running_var\", \"net.5.num_batches_tracked\". "
     ]
    }
   ],
   "source": [
    "x = torch.ones(1,1,32,32)\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load('net_params.pth'))\n",
    "prediction = net(x)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e577d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
