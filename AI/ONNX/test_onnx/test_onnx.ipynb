{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c075f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import torch\n",
    "import torch.onnx\n",
    "import onnx\n",
    "from unet import UNet\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from utils.dataset import BasicDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7314595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__: 1.4.0\n",
      "onnx.__version__: 1.6.0\n",
      "onnxruntime.__version__: 1.6.0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "onnxpath = 'test_simpleclass.onnx'\n",
    "print(\"torch.__version__:\", torch.__version__)\n",
    "print(\"onnx.__version__:\", onnx.__version__)\n",
    "print(\"onnxruntime.__version__:\", onnxruntime.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "066fc33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check: None\n"
     ]
    }
   ],
   "source": [
    "onnx_model = onnx.load(onnxpath)\n",
    "check = onnx.checker.check_model(onnx_model)\n",
    "print(\"check:\", check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff80f01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'onnx.onnx_ml_pb2.ModelProto'>\n"
     ]
    }
   ],
   "source": [
    "input = torch.ones(1,1,32,32)\n",
    "print(type(onnx_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d790b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef7b5871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (net): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            \n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension(批大小维度)\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load('net_params.pth'))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80db18a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]]], requires_grad=True)\n",
      "tensor([[ 0.1250,  0.2573, -0.3091, -0.2858,  0.1090,  0.3707, -0.1113, -0.1605,\n",
      "          0.5539,  0.5565]], grad_fn=<AddmmBackward>)\n",
      "[array([[ 0.12500986,  0.25731432, -0.3091376 , -0.28575692,  0.10895295,\n",
      "         0.3706818 , -0.11133403, -0.1605079 ,  0.5538917 ,  0.55652654]],\n",
      "      dtype=float32)]\n",
      "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-02 17:01:20.233774960 [W:onnxruntime:, graph.cc:1069 Graph] Initializer conv1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-02 17:01:20.233809399 [W:onnxruntime:, graph.cc:1069 Graph] Initializer conv1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-02 17:01:20.233815182 [W:onnxruntime:, graph.cc:1069 Graph] Initializer fc1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-02 17:01:20.233818957 [W:onnxruntime:, graph.cc:1069 Graph] Initializer fc1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-02 17:01:20.233822473 [W:onnxruntime:, graph.cc:1069 Graph] Initializer fc2.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-02 17:01:20.233825916 [W:onnxruntime:, graph.cc:1069 Graph] Initializer fc2.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-02 17:01:20.233830442 [W:onnxruntime:, graph.cc:1069 Graph] Initializer fc3.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-02 17:01:20.233835966 [W:onnxruntime:, graph.cc:1069 Graph] Initializer fc3.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-02 17:01:20.233841633 [W:onnxruntime:, graph.cc:1069 Graph] Initializer net.0.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-02 17:01:20.233847708 [W:onnxruntime:, graph.cc:1069 Graph] Initializer net.0.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-02 17:01:20.233853990 [W:onnxruntime:, graph.cc:1069 Graph] Initializer net.1.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-02 17:01:20.233857659 [W:onnxruntime:, graph.cc:1069 Graph] Initializer net.1.num_batches_tracked appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-02 17:01:20.233861497 [W:onnxruntime:, graph.cc:1069 Graph] Initializer net.1.running_mean appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-02 17:01:20.233865509 [W:onnxruntime:, graph.cc:1069 Graph] Initializer net.1.running_var appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-02 17:01:20.233869213 [W:onnxruntime:, graph.cc:1069 Graph] Initializer net.1.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-02 17:01:20.233872689 [W:onnxruntime:, graph.cc:1069 Graph] Initializer net.4.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-02 17:01:20.233876224 [W:onnxruntime:, graph.cc:1069 Graph] Initializer net.4.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-02 17:01:20.233879691 [W:onnxruntime:, graph.cc:1069 Graph] Initializer net.5.bias appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-02 17:01:20.233883158 [W:onnxruntime:, graph.cc:1069 Graph] Initializer net.5.num_batches_tracked appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-02 17:01:20.233887335 [W:onnxruntime:, graph.cc:1069 Graph] Initializer net.5.running_mean appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-02 17:01:20.233890882 [W:onnxruntime:, graph.cc:1069 Graph] Initializer net.5.running_var appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-02 17:01:20.233894449 [W:onnxruntime:, graph.cc:1069 Graph] Initializer net.5.weight appears in graph inputs and will not be treated as constant value/weight. This may prevent some of the graph optimizations, like const folding. Move it out of graph inputs if there is no need to override it, by either re-generating the model with latest exporter/converter or with the tool onnxruntime/tools/python/remove_initializer_from_input.py.\n",
      "2021-12-02 17:01:20.236145644 [W:onnxruntime:, graph.cc:3093 CleanUnusedInitializers] Removing initializer 'net.5.num_batches_tracked'. It is not used by any node and should be removed from the model.\n",
      "2021-12-02 17:01:20.236169151 [W:onnxruntime:, graph.cc:3093 CleanUnusedInitializers] Removing initializer 'conv1.bias'. It is not used by any node and should be removed from the model.\n",
      "2021-12-02 17:01:20.236176047 [W:onnxruntime:, graph.cc:3093 CleanUnusedInitializers] Removing initializer 'conv1.weight'. It is not used by any node and should be removed from the model.\n",
      "2021-12-02 17:01:20.236182783 [W:onnxruntime:, graph.cc:3093 CleanUnusedInitializers] Removing initializer 'net.1.num_batches_tracked'. It is not used by any node and should be removed from the model.\n"
     ]
    }
   ],
   "source": [
    "ort_session = onnxruntime.InferenceSession(onnxpath)\n",
    "ort_x = torch.ones(1, 1, 32, 32, requires_grad=True)\n",
    "print(ort_x)\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(ort_x)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "torch_out = net(ort_x)\n",
    "print(torch_out)\n",
    "print(ort_outs)\n",
    "# compare ONNX Runtime and PyTorch results\n",
    "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39138e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33313912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
