# intro:
    没有用recurrence and convolutions, 仅仅基于 attention mechanisms
    论文是仅仅应用在翻译上，但是后面其他人应用到了图片，video上，火爆出圈

# conclusion：
    该论文在时序性很强的文字上有很好的研究效果，作者也预测了可以把transformer时序弱化，然后应用到其他方向（图片等）
    （当然，后续很多其他人将transformer应用到了图片等，效果确实巨好！）
    

