forward阶段：
class MSNCombineConv3dBN3dReLU(nn.Module):
    def __init__(self, in_shape, conv0_c0, conv0_c1, conv0_kernel_size, conv0_stride, conv0_padding, conv1_c0, conv1_c1,
                 conv1_kernel_size, conv1_stride, conv1_padding, conv2_c0, conv2_c1, conv2_kernel_size, conv2_stride,
                 conv2_padding):
        super(MSNCombineConv3dBN3dReLU, self).__init__()
        # specific case: kernel0 = stride[0]
        self.c0, self.c1, self.c2, self.c3 = conv0_c0, conv0_c1, conv1_c1, conv2_c1
        self.k0, self.k1, self.k2 = conv0_kernel_size[1:3], conv1_kernel_size[1:3], conv2_kernel_size[1:3]
        self.s0, self.s1, self.s2 = conv0_stride[1:3], conv1_stride[1:3], conv2_stride[1:3]
        self.p0, self.p1, self.p2 = conv0_padding[1:3], conv1_padding[1:3], conv2_padding[1:3]
        self.ks0, self.ks1, self.ks2 = conv0_kernel_size[0], conv1_kernel_size[0], conv2_kernel_size[0]
        self.cc0, self.cc1, self.cc2 = self.c1 / conv0_stride[0], self.c2 / conv1_stride[0], self.c3 / conv2_stride[0]
 
        # output image shape, isp[1] = slice count in 3d conv decompose
        self.isp0 = in_shape[0:2]
 
 
 
        self.isp1 = [conv0_c1, self.isp0[1] // conv0_stride[0]]
        self.isp2 = [conv1_c1, self.isp1[1] // conv1_stride[0]]
        self.isp3 = [conv2_c1, self.isp2[1] // conv2_stride[0]]
 
        # create module 1 operation list
        self.conv2d_list0 = nn.ModuleList([nn.Conv2d(self.ks0, 1, self.k0, self.s0, self.p0, 1)
                                           for i in range(0, self.c0 * self.c1)])
        self.bn2d_list0 = nn.ModuleList([nn.BatchNorm2d(self.isp1[1])
                                         for i in range(0, self.c1)])
 
        # create module 2 operation list
        self.conv2d_list1 = nn.ModuleList([nn.Conv2d(self.ks1, 1, self.k1, self.s1, self.p1, 1)
                                           for i in range(0, self.c1 * self.c2)])
        self.bn2d_list1 = nn.ModuleList([nn.BatchNorm2d(self.isp2[1])
                                         for i in range(0, self.c2)])
 
        # create module 3 operation list
        self.conv2d_list2 = nn.ModuleList([nn.Conv2d(self.ks2, 1, self.k2, self.s2, self.p2, 1)
                                           for i in range(0, self.c2 * self.c3)])
        self.bn2d_list2 = nn.ModuleList([nn.BatchNorm2d(self.isp3[1])
                                         for i in range(0, self.c3)])
 
        # create other module
        self.relu = nn.ReLU()
 
 
    def forward(self, input):
        # input shape [1, 64, 92, 164]
        # channel  c = [1, 16, 32, 16]
        # slice count  isp[1] = [64, 8, 2, 1]
        # image data shape  isp=[1,16] [16, 8] [32, 2] [16, 1]
        # kernel stride ks = [8, 4, 2]
 
        # stage0 conv3d: kernel=[8,3,3], output shape [16, 8, , ]
        output0 = input.new_zeros(self.c1, self.isp1[1], input.shape[2], input.shape[3])
        for iout in range(0, self.c1):
            for islc in range(0, self.isp1[1]):
                kernel_id = iout
                data_slice = input[0, (islc*self.ks0):((islc+1)*self.ks0), :, :].unsqueeze(0)
                output0[iout, islc, :, :] = self.conv2d_list0[kernel_id](data_slice)
 
        # output = torch.sum(output_slc, dim=(2,), keepdim=False).unsqueeze(0)
        for i in range(0, self.c1):
            output0[i, :, :, :] = self.bn2d_list0[i](output0[i, :, :, :].unsqueeze(0))
 
        output0 = self.relu(output0)
 
        # output shape is [32, 2, :, :], kernel is
        output1 = input.new_zeros(self.c2, self.isp2[1], input.shape[2], input.shape[3])
        for iout in range(0, self.c2):
            for islc in range(0, self.isp2[1]):
                for iin in range(0, self.c1):
                    data_slice = output0[iin, (islc*self.ks1):((islc+1)*self.ks1), :, :].unsqueeze(0)
                    kernel_id = iout * self.c1 + iin
                    output_tmp = self.conv2d_list1[kernel_id](data_slice)
                    output1[iout:(iout+1), islc:(islc+1), :, :] += output_tmp
 
        for i in range(0, self.c2):
            output1[i, :, :, :] = self.bn2d_list1[i](output1[i, :, :, :].unsqueeze(0))
 
        output1 = self.relu(output1)
 
        # output shape is [16, 1, :, :] -> [1, 16, :, :]
        output2 = input.new_zeros(1, self.c3, input.shape[2], input.shape[3])
        for iout in range(0, self.c3):
            for iin in range(0, self.c2):
                data_slice = output1[iin, :, :, :].unsqueeze(0)
                kernel_id = iout * self.c2 + iin
                output2[:, iout:(iout+1), :, :] += self.conv2d_list2[kernel_id](data_slice)
 
        # relu on [1, 16, 1, :, :]
        for i in range(0, self.c3):
            output2[:, i, :, :] = self.bn2d_list2[i](output2[:, i, :, :].unsqueeze(0))
 
        output2 = self.relu(output2)
 
        return output2

字典转换：
# Copyright (c) 2021. All rights reserved.
from __future__ import print_function
import math
import torch
import torch.nn as nn
import torch.nn.functional as F
 
from msnconv3d import MSNConv3d, MSNBatchNorm3d, MSNCombineConv3dBN3dReLU
 
import re
 
 
class ConvTestNet(nn.Module):
    def __init__(self):
        super(ConvTestNet, self).__init__()
 
        self.conv3d = nn.Sequential(nn.Conv3d(1, 16, kernel_size=(8, 3, 3), stride=[8, 1, 1], padding=[0, 1, 1]),
                                    nn.BatchNorm3d(16),
                                    nn.ReLU(),
                                    nn.Conv3d(16, 32, kernel_size=(4, 3, 3), stride=[4, 1, 1], padding=[0, 1, 1]),
                                    nn.BatchNorm3d(32),
                                    nn.ReLU(),
                                    nn.Conv3d(32, 16, kernel_size=(2, 3, 3), stride=[2, 1, 1], padding=[0, 1, 1]),
                                    nn.BatchNorm3d(16),
                                    nn.ReLU()
                                    )
 
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
            elif isinstance(m, nn.Conv3d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.kernel_size[2] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm3d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()
            elif isinstance(m, nn.Linear):
                m.bias.data.zero_()
 
 
    def forward(self, x):
        x = self.conv3d(x)
        return x
 
 
class ConvTestNet3(nn.Module):
    def __init__(self):
        super(ConvTestNet3, self).__init__()
 
        self.conv3d = MSNCombineConv3dBN3dReLU([1, 64, 92, 164],
                                               1, 16, (8, 3, 3), [8, 1, 1], [0, 1, 1],
                                               16, 32, (4, 3, 3), [4, 1, 1], [0, 1, 1],
                                               32, 16, (2, 3, 3), [2, 1, 1], [0, 1, 1])
        # self.conv3d = nn.Sequential(MSNConv3d(1, 16, kernel_size=(8, 3, 3), stride=[8, 1, 1], padding=[0, 1, 1]),
        #                             nn.BatchNorm3d(16),
        #                             nn.ReLU(),
        #                             MSNConv3d(16, 32, kernel_size=(4, 3, 3), stride=[4, 1, 1], padding=[0, 1, 1]),
        #                             nn.BatchNorm3d(32),
        #                             nn.ReLU(),
        #                             MSNConv3d(32, 16, kernel_size=(2, 3, 3), stride=[2, 1, 1], padding=[0, 1, 1]),
        #                             nn.BatchNorm3d(16),
        #                             nn.ReLU()
        #                             )
 
    def convert_state(self, state_dict_outside):
        state_dict_inside_copy = self.state_dict().copy()
        state_dict_inside = self.state_dict()
        # mark conv3d dict name prefix
        conv3d_name_list_out = ['conv3d.0', 'conv3d.3', 'conv3d.6']
        conv3d_name_list_in = ['conv3d.conv2d_list0', 'conv3d.conv2d_list1', 'conv3d.conv2d_list2']
 
        #find match
        for i in range(0, len(conv3d_name_list_out)):
            key_out = conv3d_name_list_out[i]
            key_in = conv3d_name_list_in[i]
 
            val_out = None
            last_w = 0
            for key_out_iter in state_dict_outside:
                val_out = state_dict_outside[key_out_iter]
                if key_out_iter.__contains__(key_out) and key_out_iter.__contains__('weight'):
                    for key_in_iter in state_dict_inside:
                        if key_in_iter.__contains__(key_in) and key_in_iter.__contains__('weight'):
                            match_obj = re.match(r'.*'+key_in+'\.(\d+)\.weight', key_in_iter)
                            idx_in = int(match_obj[1])
                            shape_out = val_out.shape[0:2]
                            last_w = shape_out[1]
                            idx_out = [idx_in // shape_out[1], idx_in % shape_out[1]]
                            val_in = state_dict_inside[key_in_iter]
                            state_dict_inside[key_in_iter] = val_out[idx_out[0], idx_out[1], :, :, :].unsqueeze(0)
                elif key_out_iter.__contains__(key_out) and key_out_iter.__contains__('bias'):
                    for key_in_iter in state_dict_inside:
                        if key_in_iter.__contains__(key_in) and key_in_iter.__contains__('bias'):
                            match_obj = re.match(r'.*'+key_in+'\.(\d+)\.bias', key_in_iter)
                            idx_in = int(match_obj[1])
                            shape_out = val_out.shape[0]
                            idx_out = idx_in // last_w
                            mod_out = idx_in % last_w
                            if mod_out == 0:
                                state_dict_inside[key_in_iter] = val_out[idx_out].unsqueeze(0)
                            else:
                                state_dict_inside[key_in_iter][0] = 0
 
        bn3d_name_list_out = ['conv3d.1', 'conv3d.4', 'conv3d.7']
        bn3d_name_list_in = ['conv3d.bn2d_list0', 'conv3d.bn2d_list1', 'conv3d.bn2d_list2']
 
        for i in range(0, len(bn3d_name_list_out)):
            key_out = bn3d_name_list_out[i]
            key_in = bn3d_name_list_in[i]
 
            val_out = None
 
            for key_out_iter in state_dict_outside:
                val_out = state_dict_outside[key_out_iter]
                if key_out_iter.__contains__(key_out) and key_out_iter.__contains__('weight'):
                    for key_in_iter in state_dict_inside:
                        if key_in_iter.__contains__(key_in) and key_in_iter.__contains__('weight'):
                            match_obj = re.match(r'.*'+key_in+'\.(\d+)\.weight', key_in_iter)
                            idx_in = int(match_obj[1])
                            for idx_out in range(0, len(state_dict_inside[key_in_iter])):
                                state_dict_inside[key_in_iter][idx_out] = val_out[idx_in]
                elif key_out_iter.__contains__(key_out) and key_out_iter.__contains__('bias'):
                    for key_in_iter in state_dict_inside:
                        if key_in_iter.__contains__(key_in) and key_in_iter.__contains__('bias'):
                            match_obj = re.match(r'.*'+key_in+'\.(\d+)\.bias', key_in_iter)
                            idx_in = int(match_obj[1])
                            shape_out = val_out.shape[0]
                            for idx_out in range(0, len(state_dict_inside[key_in_iter])):
                                state_dict_inside[key_in_iter][idx_out] = val_out[idx_in]
                elif key_out_iter.__contains__(key_out) and key_out_iter.__contains__('running_mean'):
                    for key_in_iter in state_dict_inside:
                        if key_in_iter.__contains__(key_in) and key_in_iter.__contains__('running_mean'):
                            match_obj = re.match(r'.*'+key_in+'\.(\d+)\.running_mean', key_in_iter)
                            idx_in = int(match_obj[1])
                            for idx_out in range(0, len(state_dict_inside[key_in_iter])):
                                state_dict_inside[key_in_iter][idx_out] = val_out[idx_in]
                elif key_out_iter.__contains__(key_out) and key_out_iter.__contains__('running_val'):
                    for key_in_iter in state_dict_inside:
                        if key_in_iter.__contains__(key_in) and key_in_iter.__contains__('running_val'):
                            match_obj = re.match(r'.*'+key_in+'\.(\d+)\.running_val', key_in_iter)
                            idx_in = int(match_obj[1])
                            for idx_out in range(0, len(state_dict_inside[key_in_iter])):
                                state_dict_inside[key_in_iter][idx_out] = val_out[idx_in]
 
        self.load_state_dict(state_dict_inside)
        return
 
    def forward(self, x):
        x = self.conv3d(x)
        return x
 
 
def test():
    model1 = ConvTestNet()
    torch.save(model1.state_dict(), "model1.ckpt")
 
    state_dict1 = torch.load("model1.ckpt")
    model1.load_state_dict(state_dict1)
 
    model2 = ConvTestNet2()
 
    model3 = ConvTestNet3()
    model3.convert_state(state_dict1)
 
    input = torch.randn(1, 1, 64, 92, 164)
 
    model1.eval()
    output1 = model1(input)
 
    input3 = input[0, :, :, :, :]
    model3.eval()
    output3 = model3(input3)
 
    err_sum = torch.sum(torch.abs(output3 - output1.squeeze(2))).item()
    err_max = torch.max(torch.abs(output3 - output1.squeeze(2))).item()
 
    print("max err: %f,  total err: %f" % (err_max, err_sum))
 
    return
 
 
if __name__ == "__main__":
    test()

